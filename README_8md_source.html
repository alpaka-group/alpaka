<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>alpaka: /home/runner/work/alpaka/alpaka/README.md Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="alpaka_doxygen.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">alpaka
   </div>
   <div id="projectbrief">Abstraction Library for Parallel Kernel Acceleration</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('README_8md.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">/home/runner/work/alpaka/alpaka/README.md</div>  </div>
</div><!--header-->
<div class="contents">
<a href="README_8md.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;**alpaka** - Abstraction Library for Parallel Kernel Acceleration</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;=================================================================</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;[![Continuous Integration](https://github.com/alpaka-group/alpaka/workflows/Continuous%20Integration/badge.svg)](https://github.com/alpaka-group/alpaka/actions?query=workflow%3A%22Continuous+Integration%22)</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;[![Documentation Status](https://readthedocs.org/projects/alpaka/badge/?version=latest)](https://alpaka.readthedocs.io)</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;[![Doxygen](https://img.shields.io/badge/API-Doxygen-blue.svg)](https://alpaka-group.github.io/alpaka)</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;[![Language](https://img.shields.io/badge/language-C%2B%2B14-orange.svg)](https://isocpp.org/)</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;[![Platforms](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20mac-lightgrey.svg)](https://github.com/alpaka-group/alpaka)</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;[![License](https://img.shields.io/badge/license-MPL--2.0-blue.svg)](https://www.mozilla.org/en-US/MPL/2.0/)</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;![alpaka](docs/logo/alpaka_401x135.png)</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;The **alpaka** library is a header-only C++14 abstraction library for accelerator development.</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;Its aim is to provide performance portability across accelerators through the abstraction (not hiding!) of the underlying levels of parallelism.</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;It is platform independent and supports the concurrent and cooperative use of multiple devices such as the hosts CPU as well as attached accelerators as for instance CUDA GPUs and Xeon Phis (currently native execution only).</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;A multitude of accelerator back-end variants using CUDA, OpenMP (2.0/4.0), Boost.Fiber, std::thread and also serial execution is provided and can be selected depending on the device.</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;Only one implementation of the user kernel is required by representing them as function objects with a special interface.</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;There is no need to write special CUDA, OpenMP or custom threading code.</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;Accelerator back-ends can be mixed within a device queue.</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;The decision which accelerator back-end executes which kernel can be made at runtime.</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;The abstraction used is very similar to the CUDA grid-blocks-threads division strategy.</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;Algorithms that should be parallelized have to be divided into a multi-dimensional grid consisting of small uniform work items.</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;These functions are called kernels and are executed in parallel threads.</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;The threads in the grid are organized in blocks.</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;All threads in a block are executed in parallel and can interact via fast shared memory.</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;Blocks are executed independently and can not interact in any way.</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;The block execution order is unspecified and depends on the accelerator in use.</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;By using this abstraction the execution can be optimally adapted to the available hardware.</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;Software License</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;----------------</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;**alpaka** is licensed under **MPL-2.0**.</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;Documentation</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;-------------</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;The alpaka documentation can be found in the [online manual](https://alpaka.readthedocs.io).</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;The documentation files in [`.rst` (reStructuredText)](https://www.sphinx-doc.org/en/stable/rest.html) format are located in the `docs` subfolder of this repository.</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;The [source code documentation](https://alpaka-group.github.io/alpaka/) is generated with [doxygen](http://www.doxygen.org).</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;Accelerator Back-ends</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;---------------------</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;|Accelerator Back-end|Lib/API|Devices|Execution strategy grid-blocks|Execution strategy block-threads|</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;|---|---|---|---|---|</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;|Serial|n/a|Host CPU (single core)|sequential|sequential (only 1 thread per block)|</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;|OpenMP 2.0+ blocks|OpenMP 2.0+|Host CPU (multi core)|parallel (preemptive multitasking)|sequential (only 1 thread per block)|</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;|OpenMP 2.0+ threads|OpenMP 2.0+|Host CPU (multi core)|sequential|parallel (preemptive multitasking)|</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;|OpenMP 4.0+ (CPU)|OpenMP 4.0+|Host CPU (multi core)|parallel (undefined)|parallel (preemptive multitasking)|</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;| std::thread | std::thread |Host CPU (multi core)|sequential|parallel (preemptive multitasking)|</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;| Boost.Fiber | boost::fibers::fiber |Host CPU (single core)|sequential|parallel (cooperative multitasking)|</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;|TBB|TBB 2.2+|Host CPU (multi core)|parallel (preemptive multitasking)|sequential (only 1 thread per block)|</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;|CUDA|CUDA 9.0+|NVIDIA GPUs|parallel (undefined)|parallel (lock-step within warps)|</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;|HIP(clang)|[HIP 3.5+](https://github.com/ROCm-Developer-Tools/HIP)|AMD GPUs |parallel (undefined)|parallel (lock-step within warps)|</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;Supported Compilers</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;-------------------</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;This library uses C++14 (or newer when available).</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;|Accelerator Back-end|gcc 5.5 &lt;br/&gt; (Linux)|gcc 6.4/7.3 &lt;br/&gt; (Linux)|gcc 8.1 &lt;br/&gt; (Linux)|gcc 9.1 &lt;br/&gt; (Linux)|gcc 10.1 &lt;br/&gt; (Linux)|clang 4 &lt;br/&gt; (Linux)|clang 5 &lt;br/&gt; (Linux)|clang 6 &lt;br/&gt; (Linux)|clang 7 &lt;br/&gt; (Linux)|clang 8 &lt;br/&gt; (Linux)|clang 9 &lt;br/&gt; (Linux)|clang 10 &lt;br/&gt; (Linux)|Apple LLVM 11.0-11.4 &lt;br/&gt; (macOS)|MSVC 2017 &lt;br/&gt; (Windows)|MSVC 2019 &lt;br/&gt; (Windows)|</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;|Serial|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;|OpenMP 2.0+ blocks|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:x:|:white_check_mark:|:white_check_mark:|</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;|OpenMP 2.0+ threads|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:x:|:white_check_mark:|:white_check_mark:|</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;|OpenMP 4.0+ (CPU)|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:x:|:x:|:x:|</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;| std::thread |:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;| Boost.Fiber |:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:x:|:white_check_mark:|:white_check_mark:|</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;|TBB|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:white_check_mark:|:x:|:x:|</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;|CUDA (nvcc)|:white_check_mark: &lt;br/&gt; (CUDA 9.0-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 9.2-11.1) |:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1) |:white_check_mark: &lt;br/&gt; (CUDA 11.0-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 11.1)|:white_check_mark: &lt;br/&gt; (CUDA 9.1-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 11.0-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 11.1)|:x:|:white_check_mark: &lt;br/&gt; (CUDA 10.0-11.1)|:white_check_mark: &lt;br/&gt; (CUDA 10.1-11.1)|</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;|CUDA (clang) | - | - | - | - | - | - | - | :white_check_mark: &lt;br/&gt; (CUDA 9.0) | :white_check_mark: &lt;br/&gt; (CUDA 9.0-9.2) | :white_check_mark: &lt;br/&gt; (CUDA 9.0-10.0) | :white_check_mark: &lt;br/&gt; (CUDA 9.2-10.1) | :white_check_mark: &lt;br/&gt; (CUDA 9.2-10.1) | - | - | - |</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;|[HIP](https://alpaka.readthedocs.io/en/latest/install/HIP.html) (clang)|:white_check_mark: |:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|:x:|</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;Other compilers or combinations marked with :x: in the table above may work but are not tested in CI and are therefore not explicitly supported.</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;Dependencies</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;------------</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;[Boost](https://boost.org/) 1.65.1+ is the only mandatory external dependency.</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;The **alpaka** library itself just requires header-only libraries.</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;However some of the accelerator back-end implementations require different boost libraries to be built.</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;When an accelerator back-end using *Boost.Fiber* is enabled, `boost-fiber` and all of its dependencies are required to be built in C++14 mode `./b2 cxxflags=&quot;-std=c++14&quot;`.</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;When *Boost.Fiber* is enabled and alpaka is built in C++17 mode with clang and libstc++, Boost &gt;= 1.67.0 is required.</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;When an accelerator back-end using *CUDA* is enabled, version *9.0* of the *CUDA SDK* is the minimum requirement.</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;*NOTE*: When using nvcc as *CUDA* compiler, the *CUDA accelerator back-end* can not be enabled together with the *Boost.Fiber accelerator back-end* due to bugs in the nvcc compiler.</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;*NOTE*: When using clang as a native *CUDA* compiler, the *CUDA accelerator back-end* can not be enabled together with the *Boost.Fiber accelerator back-end* or any *OpenMP accelerator back-end* because this combination is currently unsupported.</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;*NOTE*: Separable compilation is only supported when using nvcc, not with clang as native *CUDA* compiler. It is disabled by default and can be enabled via the CMake flag `ALPAKA_CUDA_NVCC_SEPARABLE_COMPILATION`.</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;When an accelerator back-end using *OpenMP* is enabled, the compiler and the platform have to support the corresponding minimum *OpenMP* version.</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;When an accelerator back-end using *TBB* is enabled, the compiler and the platform have to support the corresponding minimum *TBB* version.</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;Usage</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;-----</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;The library is header only so nothing has to be built.</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;CMake 3.15+ is required to provide the correct defines and include paths.</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;Just call `ALPAKA_ADD_EXECUTABLE` instead of `CUDA_ADD_EXECUTABLE` or `ADD_EXECUTABLE` and the difficulties of the CUDA nvcc compiler in handling `.cu` and `.cpp` files are automatically taken care of.</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;Source files do not need any special file ending.</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;Examples of how to utilize alpaka within CMake can be found in the `example` folder.</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;The whole alpaka library can be included with: `#include &lt;alpaka/alpaka.hpp&gt;`</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;Code that is not intended to be utilized by the user is hidden in the `detail` namespace.</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;Furthermore, for a CUDA-like experience when adopting alpaka we provide the library [*cupla*](https://github.com/alpaka-group/cupla).</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;It enables a simple and straightforward way of porting existing CUDA applications to alpaka and thus to a variety of accelerators.</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;Introduction</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;------------</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;For a quick introduction, feel free to playback the recording of our presentation at</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;[GTC 2016](http://mygtc.gputechconf.com/quicklink/858sI36):</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160; - E. Zenker, R. Widera, G. Juckeland et al.,</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;   *Porting the Plasma Simulation PIConGPU to Heterogeneous Architectures with Alpaka*,</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;   [video link (39 min)](http://on-demand.gputechconf.com/gtc/2016/video/S6298.html)</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;Citing alpaka</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;-------------</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;Currently all authors of **alpaka** are scientists or connected with</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;research. For us to justify the importance and impact of our work, please</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;consider citing us accordingly in your derived work and publications:</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;```latex</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;% Peer-Reviewed Publication %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;%</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;% Peer reviewed and accepted publication in</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;%   &quot;2nd International Workshop on Performance Portable</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;%    Programming Models for Accelerators (P^3MA)&quot;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;% colocated with the</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;%   &quot;2017 ISC High Performance Conference&quot;</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;%   in Frankfurt, Germany</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;@inproceedings{MathesP3MA2017,</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;  author    = {{Matthes}, A. and {Widera}, R. and {Zenker}, E. and {Worpitz}, B. and</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;               {Huebl}, A. and {Bussmann}, M.},</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;  title     = {Tuning and optimization for a variety of many-core architectures without changing a single line of implementation code</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;               using the Alpaka library},</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;  archivePrefix = &quot;arXiv&quot;,</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;  eprint    = {1706.10086},</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;  keywords  = {Computer Science - Distributed, Parallel, and Cluster Computing},</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  day       = {30},</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;  month     = {Jun},</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;  year      = {2017},</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;  url       = {https://arxiv.org/abs/1706.10086},</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;}</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;% Peer-Reviewed Publication %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;%</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;% Peer reviewed and accepted publication in</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;%   &quot;The Sixth International Workshop on</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;%    Accelerators and Hybrid Exascale Systems (AsHES)&quot;</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;% at the</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;%   &quot;30th IEEE International Parallel and Distributed</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;%    Processing Symposium&quot; in Chicago, IL, USA</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;@inproceedings{ZenkerAsHES2016,</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;  author    = {Erik Zenker and Benjamin Worpitz and Ren{\&#39;{e}} Widera</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;               and Axel Huebl and Guido Juckeland and</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;               Andreas Kn{\&quot;{u}}pfer and Wolfgang E. Nagel and Michael Bussmann},</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;  title     = {Alpaka - An Abstraction Library for Parallel Kernel Acceleration},</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;  archivePrefix = &quot;arXiv&quot;,</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;  eprint    = {1602.08477},</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;  keywords  = {Computer science;CUDA;Mathematical Software;nVidia;OpenMP;Package;</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;               performance portability;Portability;Tesla K20;Tesla K80},</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;  day       = {23},</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;  month     = {May},</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;  year      = {2016},</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;  publisher = {IEEE Computer Society},</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;  url       = {http://arxiv.org/abs/1602.08477},</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;}</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;% Original Work: Benjamin Worpitz&#39; Master Thesis %%%%%%%%%%</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;%</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;@MasterThesis{Worpitz2015,</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;  author = {Benjamin Worpitz},</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;  title  = {Investigating performance portability of a highly scalable</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;            particle-in-cell simulation code on various multi-core</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;            architectures},</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;  school = {{Technische Universit{\&quot;{a}}t Dresden}},</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;  month  = {Sep},</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;  year   = {2015},</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;  type   = {Master Thesis},</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;  doi    = {10.5281/zenodo.49768},</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;  url    = {http://dx.doi.org/10.5281/zenodo.49768}</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;}</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;```</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;</div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;Authors</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;-------</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;### Maintainers and Core Developers</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;- Benjamin Worpitz (original author)</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;- Rene Widera</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;### Former Members, Contributions and Thanks</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;- Dr. Michael Bussmann</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;- Axel Huebl</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;- Erik Zenker</div></div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="README_8md.html">README.md</a></li>
    <li class="footer">Generated on Mon Nov 9 2020 18:48:08 for alpaka by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
