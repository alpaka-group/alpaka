<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>alpaka: /home/runner/work/alpaka/alpaka/include/alpaka/kernel/TaskKernelGpuUniformCudaHipRt.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="alpaka_doxygen.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">alpaka
   </div>
   <div id="projectbrief">Abstraction Library for Parallel Kernel Acceleration</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('TaskKernelGpuUniformCudaHipRt_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">TaskKernelGpuUniformCudaHipRt.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="TaskKernelGpuUniformCudaHipRt_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/* Copyright 2022 Benjamin Worpitz, Erik Zenker, Matthias Werner, Ren√© Widera, Jan Stephan, Andrea Bocci, Bernhard</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * Manfred Gruber, Antonio Di Pilato</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * This file is part of alpaka.</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> *</span></div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * This Source Code Form is subject to the terms of the Mozilla Public</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * License, v. 2.0. If a copy of the MPL was not distributed with this</span></div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * file, You can obtain one at http://mozilla.org/MPL/2.0/.</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> */</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160; </div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#pragma once</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160; </div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#if defined(ALPAKA_ACC_GPU_CUDA_ENABLED) || defined(ALPAKA_ACC_GPU_HIP_ENABLED)</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160; </div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#    if !defined(ALPAKA_HOST_ONLY)</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160; </div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="BoostPredef_8hpp.html">alpaka/core/BoostPredef.hpp</a>&gt;</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160; </div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#        if defined(ALPAKA_ACC_GPU_CUDA_ENABLED) &amp;&amp; !BOOST_LANG_CUDA</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#            error If ALPAKA_ACC_GPU_CUDA_ENABLED is set, the compiler has to support CUDA!</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160; </div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#        if defined(ALPAKA_ACC_GPU_HIP_ENABLED) &amp;&amp; !BOOST_LANG_HIP</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#            error If ALPAKA_ACC_GPU_HIP_ENABLED is set, the compiler has to support HIP!</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; </div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="comment">// Specialized traits.</span></div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="acc_2Traits_8hpp.html">alpaka/acc/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="dev_2Traits_8hpp.html">alpaka/dev/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="dim_2Traits_8hpp.html">alpaka/dim/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="idx_2Traits_8hpp.html">alpaka/idx/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="pltf_2Traits_8hpp.html">alpaka/pltf/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="queue_2Traits_8hpp.html">alpaka/queue/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160; </div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="comment">// Backend specific includes.</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;<span class="preprocessor">#        if defined(ALPAKA_ACC_GPU_CUDA_ENABLED)</span></div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="preprocessor">#            include &lt;<a class="code" href="Cuda_8hpp.html">alpaka/core/Cuda.hpp</a>&gt;</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="preprocessor">#        else</span></div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="preprocessor">#            include &lt;<a class="code" href="Hip_8hpp.html">alpaka/core/Hip.hpp</a>&gt;</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160; </div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="comment">// Implementation details.</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="AccGpuUniformCudaHipRt_8hpp.html">alpaka/acc/AccGpuUniformCudaHipRt.hpp</a>&gt;</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="Decay_8hpp.html">alpaka/core/Decay.hpp</a>&gt;</span></div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="DemangleTypeNames_8hpp.html">alpaka/core/DemangleTypeNames.hpp</a>&gt;</span></div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="RemoveRestrict_8hpp.html">alpaka/core/RemoveRestrict.hpp</a>&gt;</span></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="DevUniformCudaHipRt_8hpp.html">alpaka/dev/DevUniformCudaHipRt.hpp</a>&gt;</span></div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="kernel_2Traits_8hpp.html">alpaka/kernel/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="QueueUniformCudaHipRtBlocking_8hpp.html">alpaka/queue/QueueUniformCudaHipRtBlocking.hpp</a>&gt;</span></div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="QueueUniformCudaHipRtNonBlocking_8hpp.html">alpaka/queue/QueueUniformCudaHipRtNonBlocking.hpp</a>&gt;</span></div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="WorkDivMembers_8hpp.html">alpaka/workdiv/WorkDivMembers.hpp</a>&gt;</span></div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160; </div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="preprocessor">#            include &lt;<a class="code" href="acc_2Traits_8hpp.html">alpaka/acc/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="preprocessor">#            include &lt;<a class="code" href="dev_2Traits_8hpp.html">alpaka/dev/Traits.hpp</a>&gt;</span></div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="preprocessor">#            include &lt;<a class="code" href="WorkDivHelpers_8hpp.html">alpaka/workdiv/WorkDivHelpers.hpp</a>&gt;</span></div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160; </div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;<span class="preprocessor">#        include &lt;<a class="code" href="BoostPredef_8hpp.html">alpaka/core/BoostPredef.hpp</a>&gt;</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160; </div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;<span class="preprocessor">#        include &lt;stdexcept&gt;</span></div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;<span class="preprocessor">#        include &lt;tuple&gt;</span></div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;<span class="preprocessor">#        include &lt;type_traits&gt;</span></div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;<span class="preprocessor">#            include &lt;iostream&gt;</span></div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160; </div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacealpaka.html">alpaka</a></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;{</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="keyword">namespace </span>detail</div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    {<span class="comment"></span></div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;<span class="comment">        //! The GPU CUDA/HIP kernel entry point.</span></div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="comment"></span>        <span class="comment">// \NOTE: &#39;A __global__ function or function template cannot have a trailing return type.&#39;</span></div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;        <span class="comment">// We have put the function into a shallow namespace and gave it a short name, so the mangled name in the</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        <span class="comment">// profiler (e.g. ncu) is as shorter as possible.</span></div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00077"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">   77</a></span>&#160;        __global__ <span class="keywordtype">void</span> <a class="code" href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">gpuKernel</a>(</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;            <a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span> threadElemExtent,</div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;            TKernelFnObj <span class="keyword">const</span> kernelFnObj,</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;            TArgs... args)</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;        {</div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;<span class="preprocessor">#        if BOOST_ARCH_PTX &amp;&amp; (BOOST_ARCH_PTX &lt; BOOST_VERSION_NUMBER(2, 0, 0))</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;<span class="preprocessor">#            error &quot;Device capability &gt;= 2.0 is required!&quot;</span></div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160; </div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;            <span class="keyword">const</span> TAcc acc(threadElemExtent);</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160; </div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;<span class="comment">// with clang it is not possible to query std::result_of for a pure device lambda created on the host side</span></div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;<span class="preprocessor">#        if !(BOOST_COMP_CLANG_CUDA &amp;&amp; BOOST_COMP_CLANG)</span></div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;            static_assert(</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                std::is_same_v&lt;decltype(kernelFnObj(<span class="keyword">const_cast&lt;</span>TAcc const&amp;<span class="keyword">&gt;</span>(acc), args...)), <span class="keywordtype">void</span>&gt;,</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                <span class="stringliteral">&quot;The TKernelFnObj is required to return void!&quot;</span>);</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;            kernelFnObj(<span class="keyword">const_cast&lt;</span>TAcc const&amp;<span class="keyword">&gt;</span>(acc), args...);</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        }</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    } <span class="comment">// namespace detail</span></div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160; </div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <span class="keyword">namespace </span>uniform_cuda_hip</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    {</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;        <span class="keyword">namespace </span>detail</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;        {</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;            <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx&gt;</div>
<div class="line"><a name="l00103"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">  103</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">auto</span> <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">checkVecOnly3Dim</a>(<a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span>&amp; vec) -&gt; <span class="keywordtype">void</span></div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;            {</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt; 0)</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;                {</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;                    <span class="keywordflow">for</span>(<span class="keyword">auto</span> i = <a class="code" href="namespacealpaka_1_1math.html#ad1a3c72853dc08a5e54e532f25a08988">std::min</a>(<span class="keyword">typename</span> TDim::value_type{3}, TDim::value); i &lt; TDim::value; ++i)</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                    {</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                        <span class="keywordflow">if</span>(vec[TDim::value - 1u - i] != 1)</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                        {</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                            <span class="keywordflow">throw</span> std::runtime_error(</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                                <span class="stringliteral">&quot;The CUDA/HIP accelerator supports a maximum of 3 dimensions. All &quot;</span></div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;                                <span class="stringliteral">&quot;work division extents of the dimensions higher 3 have to be 1!&quot;</span>);</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;                        }</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;                    }</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;                }</div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;            }</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160; </div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;            <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx&gt;</div>
<div class="line"><a name="l00120"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">  120</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">auto</span> <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">convertVecToUniformCudaHipDim</a>(<a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span>&amp; vec) -&gt; dim3</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;            {</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;                dim3 dim(1, 1, 1);</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 1)</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                    dim.x = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 1u]);</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 2)</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;                    dim.y = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 2u]);</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 3)</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;                    dim.z = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 3u]);</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;                <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">checkVecOnly3Dim</a>(vec);</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;                <span class="keywordflow">return</span> dim;</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            }</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        } <span class="comment">// namespace detail</span></div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    } <span class="comment">// namespace uniform_cuda_hip</span></div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;<span class="comment">    //! The GPU CUDA/HIP accelerator execution task.</span></div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;<span class="comment"></span>    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00137"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">  137</a></span>&#160;    <span class="keyword">class </span><a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a> final : <span class="keyword">public</span> <a class="code" href="classalpaka_1_1WorkDivMembers.html">WorkDivMembers</a>&lt;TDim, TIdx&gt;</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    {</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    <span class="keyword">public</span>:</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TWorkDiv&gt;</div>
<div class="line"><a name="l00141"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">  141</a></span>&#160;        <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">TaskKernelGpuUniformCudaHipRt</a>(</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;            TWorkDiv&amp;&amp; workDiv,</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;            TKernelFnObj <span class="keyword">const</span>&amp; kernelFnObj,</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;            TArgs&amp;&amp;... args)</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;            : <a class="code" href="classalpaka_1_1WorkDivMembers.html">WorkDivMembers</a>&lt;TDim, TIdx&gt;(std::forward&lt;TWorkDiv&gt;(workDiv))</div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;            , <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">m_kernelFnObj</a>(kernelFnObj)</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;            , <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">m_args</a>(std::forward&lt;TArgs&gt;(args)...)</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        {</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;            static_assert(</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                <a class="code" href="namespacealpaka.html#aee3fb80b82e8f3e9601195afb0b8c34c">Dim</a>&lt;std::decay_t&lt;TWorkDiv&gt;&gt;::value == TDim::value,</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;                <span class="stringliteral">&quot;The work division and the execution task have to be of the same dimensionality!&quot;</span>);</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;        }</div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160; </div>
<div class="line"><a name="l00154"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">  154</a></span>&#160;        TKernelFnObj <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">m_kernelFnObj</a>;</div>
<div class="line"><a name="l00155"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">  155</a></span>&#160;        std::tuple&lt;remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;&gt;...&gt; <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">m_args</a>;</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    };</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160; </div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <span class="keyword">namespace </span>trait</div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    {<span class="comment"></span></div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task accelerator type trait specialization.</span></div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1AccType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_b7d5109d450cd376a8ec278df7986307.html">  162</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1AccType.html">AccType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        {</div>
<div class="line"><a name="l00164"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1AccType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_b7d5109d450cd376a8ec278df7986307.html#af939da8626ba47432a68e612435b3f7f">  164</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">type</a> = <a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>;</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        };</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task device type trait specialization.</span></div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DevType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_748136d18cba1bf097b4b40671af9556.html">  169</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1DevType.html">DevType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        {</div>
<div class="line"><a name="l00171"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DevType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_748136d18cba1bf097b4b40671af9556.html#ac6bd4bc93360150aeefee20bdd24e5ae">  171</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="classalpaka_1_1DevUniformCudaHipRt.html">type</a> = <a class="code" href="classalpaka_1_1DevUniformCudaHipRt.html">DevUniformCudaHipRt&lt;TApi&gt;</a>;</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;        };</div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task dimension getter trait specialization.</span></div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html">  176</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1DimType.html">DimType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        {</div>
<div class="line"><a name="l00178"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">  178</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">type</a> = TDim;</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;        };</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="comment">        //! The CPU CUDA/HIP execution task platform type trait specialization.</span></div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00183"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1PltfType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDimf72504c03e3e168797d44ff03c491c2d.html">  183</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1PltfType.html">PltfType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;        {</div>
<div class="line"><a name="l00185"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1PltfType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDimf72504c03e3e168797d44ff03c491c2d.html#a71a44e9d2eefc6fa45f243a1020c2c44">  185</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="classalpaka_1_1PltfUniformCudaHipRt.html">type</a> = <a class="code" href="classalpaka_1_1PltfUniformCudaHipRt.html">PltfUniformCudaHipRt&lt;TApi&gt;</a>;</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;        };</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task idx type trait specialization.</span></div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00190"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html">  190</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1IdxType.html">IdxType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;        {</div>
<div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html#a3661e7ff93f5ec2d0b6929c6a790f564">  192</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">type</a> = <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>;</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;        };</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;<span class="comment">        //! The CUDA/HIP non-blocking kernel enqueue trait specialization.</span></div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00197"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtNonBlocking_3_01TApi_01_4_00_01TaskKercda831e3343a928a98cd81e7d01f0f88.html">  197</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1Enqueue.html">Enqueue</a>&lt;</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;            <a class="code" href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">QueueUniformCudaHipRtNonBlocking</a>&lt;TApi&gt;,</div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;            <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;        {</div>
<div class="line"><a name="l00201"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtNonBlocking_3_01TApi_01_4_00_01TaskKercda831e3343a928a98cd81e7d01f0f88.html#a4baf425759162472813f919548823adb">  201</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">static</span> <span class="keyword">auto</span> <a class="code" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtNonBlocking_3_01TApi_01_4_00_01TaskKercda831e3343a928a98cd81e7d01f0f88.html#a4baf425759162472813f919548823adb">enqueue</a>(</div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;                <a class="code" href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">QueueUniformCudaHipRtNonBlocking&lt;TApi&gt;</a>&amp; queue,</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;                <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;</a> <span class="keyword">const</span>&amp; task) -&gt; <span class="keywordtype">void</span></div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;            {</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;                <a class="code" href="Debug_8hpp.html#ac556c317f934c69c8c8c083c5068f681">ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</a>;</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;                <span class="comment">// TODO: Check that (sizeof(TKernelFnObj) * m_3uiBlockThreadExtent.prod()) &lt; available memory idx</span></div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160; </div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                <span class="comment">// std::size_t printfFifoSize;</span></div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot;INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;                <span class="comment">// TApi::deviceSetLimit(TApi::limitPrintfFifoSize, printfFifoSize*10);</span></div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot;INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> gridBlockExtent = getWorkDiv&lt;Grid, Blocks&gt;(task);</div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockThreadExtent = getWorkDiv&lt;Block, Threads&gt;(task);</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> threadElemExtent = getWorkDiv&lt;Thread, Elems&gt;(task);</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160; </div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;                dim3 <span class="keyword">const</span> gridDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(gridBlockExtent);</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;                dim3 <span class="keyword">const</span> blockDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(blockThreadExtent);</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">uniform_cuda_hip::detail::checkVecOnly3Dim</a>(threadElemExtent);</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160; </div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; gridDim: &quot;</span> &lt;&lt; gridDim.z &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; gridDim.y &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; gridDim.x</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; blockDim: &quot;</span> &lt;&lt; blockDim.z &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; blockDim.y &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; blockDim.x &lt;&lt; std::endl;</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160; </div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;                <span class="comment">// This checks for a valid work division that is also compliant with the maxima of the accelerator.</span></div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;                <span class="keywordflow">if</span>(!isValidWorkDiv&lt;TAcc&gt;(<a class="code" href="namespacealpaka.html#aa4fe5980725182b3306caf3167053a75">getDev</a>(queue), task))</div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;                {</div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;                    <span class="keywordflow">throw</span> std::runtime_error(</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;                        <span class="stringliteral">&quot;The given work division is not valid or not supported by the device of type &quot;</span></div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;                        + <a class="code" href="namespacealpaka.html#ac49b3c4b09c8a7455e8f88faa51484df">getAccName</a>&lt;<a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>&gt;() + <span class="stringliteral">&quot;!&quot;</span>);</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;                }</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160; </div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                <span class="comment">// Get the size of the block shared dynamic memory.</span></div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockSharedMemDynSizeBytes = <a class="code" href="namespacealpaka_1_1core.html#a3bc48ef7c999409550fcbe1a948d6f31">std::apply</a>(</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;<a class="code" href="Decay_8hpp.html#afba6dfdddd358c0ee5a1c6406afd2c11">ALPAKA_DECAY_T</a>(TArgs)&gt; <span class="keyword">const</span>&amp;... args) {</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;                        <span class="keywordflow">return</span> getBlockSharedMemDynSizeBytes&lt;TAcc&gt;(</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;                            task.m_kernelFnObj,</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;                            blockThreadExtent,</div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                            threadElemExtent,</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;                            args...);</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;                    },</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160; </div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;                <span class="comment">// Log the block shared memory idx.</span></div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; BlockSharedMemDynSizeBytes: &quot;</span> &lt;&lt; blockSharedMemDynSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;                          &lt;&lt; std::endl;</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;                <span class="keyword">auto</span> kernelName = alpaka::detail::</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;                    gpuKernel&lt;TKernelFnObj, TApi, TAcc, TDim, TIdx, remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;&gt;...&gt;;</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160; </div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;                <span class="comment">// Log the function attributes.</span></div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;                <span class="keyword">typename</span> TApi::FuncAttributes_t funcAttrs;</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;                TApi::funcGetAttributes(&amp;funcAttrs, kernelName);</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; binaryVersion: &quot;</span> &lt;&lt; funcAttrs.binaryVersion</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; constSizeBytes: &quot;</span> &lt;&lt; funcAttrs.constSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; localSizeBytes: &quot;</span> &lt;&lt; funcAttrs.localSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; maxThreadsPerBlock: &quot;</span> &lt;&lt; funcAttrs.maxThreadsPerBlock</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; numRegs: &quot;</span> &lt;&lt; funcAttrs.numRegs &lt;&lt; <span class="stringliteral">&quot; ptxVersion: &quot;</span> &lt;&lt; funcAttrs.ptxVersion</div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; sharedSizeBytes: &quot;</span> &lt;&lt; funcAttrs.sharedSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160; </div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;                <span class="comment">// Set the current device.</span></div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;                <a class="code" href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a>(TApi::setDevice(queue.m_spQueueImpl-&gt;m_dev.getNativeHandle()));</div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;                <span class="comment">// Enqueue the kernel execution.</span></div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;                <span class="comment">// \NOTE: No const reference (const &amp;) is allowed as the parameter type because the kernel launch</span></div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                <span class="comment">// language extension expects the arguments by value. This forces the type of a float argument given</span></div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;                <span class="comment">// with std::forward to this function to be of type float instead of e.g. &quot;float const &amp; __ptr64&quot;</span></div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;                <span class="comment">// (MSVC). If not given by value, the kernel launch code does not copy the value but the pointer to the</span></div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;                <span class="comment">// value location.</span></div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;                <a class="code" href="namespacealpaka_1_1core.html#a3bc48ef7c999409550fcbe1a948d6f31">std::apply</a>(</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;<a class="code" href="Decay_8hpp.html#afba6dfdddd358c0ee5a1c6406afd2c11">ALPAKA_DECAY_T</a>(TArgs)&gt; <span class="keyword">const</span>&amp;... args)</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;                    {</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                        kernelName&lt;&lt;&lt;</div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                            gridDim,</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;                            blockDim,</div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                            <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(blockSharedMemDynSizeBytes),</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;                            queue.getNativeHandle()&gt;&gt;&gt;(threadElemExtent, task.m_kernelFnObj, args...);</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;                    },</div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160; </div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                <span class="keywordflow">if</span> constexpr(<a class="code" href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a> &gt;= <a class="code" href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a>)</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                {</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;                    <span class="comment">// Wait for the kernel execution to finish but do not check error return of this call.</span></div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                    <span class="comment">// Do not use the alpaka::wait method because it checks the error itself but we want to give a</span></div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;                    <span class="comment">// custom error message.</span></div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                    std::ignore = TApi::streamSynchronize(queue.getNativeHandle());</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                    <span class="keyword">auto</span> <span class="keyword">const</span> msg = std::string{</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;                        <span class="stringliteral">&quot;&#39;execution of kernel: &#39;&quot;</span> + std::string{core::demangled&lt;TKernelFnObj&gt;} + <span class="stringliteral">&quot;&#39; failed with&quot;</span>};</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;                    ::alpaka::uniform_cuda_hip::detail::rtCheckLastError&lt;TApi, true&gt;(msg.c_str(), __FILE__, __LINE__);</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;                }</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;            }</div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;        };</div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment">        //! The CUDA/HIP synchronous kernel enqueue trait specialization.</span></div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00304"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtBlocking_3_01TApi_01_4_00_01TaskKernelc6360c0fc744d397d00b5014e3524b9c.html">  304</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1Enqueue.html">Enqueue</a>&lt;</div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;            <a class="code" href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">QueueUniformCudaHipRtBlocking</a>&lt;TApi&gt;,</div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;            <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, <a class="code" href="structalpaka_1_1trait_1_1TIdx.html">TIdx</a>, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;        {</div>
<div class="line"><a name="l00308"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtBlocking_3_01TApi_01_4_00_01TaskKernelc6360c0fc744d397d00b5014e3524b9c.html#a148631736adb9a133a5db69d73bdf8c1">  308</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">static</span> <span class="keyword">auto</span> <a class="code" href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtBlocking_3_01TApi_01_4_00_01TaskKernelc6360c0fc744d397d00b5014e3524b9c.html#a148631736adb9a133a5db69d73bdf8c1">enqueue</a>(</div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;                <a class="code" href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">QueueUniformCudaHipRtBlocking&lt;TApi&gt;</a>&amp; queue,</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;                <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;</a> <span class="keyword">const</span>&amp; task) -&gt; <span class="keywordtype">void</span></div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;            {</div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;                <a class="code" href="Debug_8hpp.html#ac556c317f934c69c8c8c083c5068f681">ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</a>;</div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;                <span class="comment">// TODO: Check that (sizeof(TKernelFnObj) * m_3uiBlockThreadExtent.prod()) &lt; available memory idx</span></div>
<div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160; </div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;                <span class="comment">// std::size_t printfFifoSize;</span></div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot;INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;                <span class="comment">// TApi::deviceSetLimit(TApi::limitPrintfFifoSize, printfFifoSize*10);</span></div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot;INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> gridBlockExtent = getWorkDiv&lt;Grid, Blocks&gt;(task);</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockThreadExtent = getWorkDiv&lt;Block, Threads&gt;(task);</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> threadElemExtent = getWorkDiv&lt;Thread, Elems&gt;(task);</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160; </div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                dim3 <span class="keyword">const</span> gridDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(gridBlockExtent);</div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;                dim3 <span class="keyword">const</span> blockDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(blockThreadExtent);</div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;                <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">uniform_cuda_hip::detail::checkVecOnly3Dim</a>(threadElemExtent);</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160; </div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot;gridDim: &quot;</span> &lt;&lt; gridDim.z &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; gridDim.y &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; gridDim.x &lt;&lt; std::endl;</div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot;blockDim: &quot;</span> &lt;&lt; blockDim.z &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; blockDim.y &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; blockDim.x</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;                          &lt;&lt; std::endl;</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160; </div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                <span class="comment">// This checks for a valid work division that is also compliant with the maxima of the accelerator.</span></div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                <span class="keywordflow">if</span>(!isValidWorkDiv&lt;TAcc&gt;(<a class="code" href="namespacealpaka.html#aa4fe5980725182b3306caf3167053a75">getDev</a>(queue), task))</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;                {</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;                    <span class="keywordflow">throw</span> std::runtime_error(</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                        <span class="stringliteral">&quot;The given work division is not valid or not supported by the device of type &quot;</span></div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                        + <a class="code" href="namespacealpaka.html#ac49b3c4b09c8a7455e8f88faa51484df">getAccName</a>&lt;<a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>&gt;() + <span class="stringliteral">&quot;!&quot;</span>);</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;                }</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160; </div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                <span class="comment">// Get the size of the block shared dynamic memory.</span></div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockSharedMemDynSizeBytes = <a class="code" href="namespacealpaka_1_1core.html#a3bc48ef7c999409550fcbe1a948d6f31">std::apply</a>(</div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;<a class="code" href="Decay_8hpp.html#afba6dfdddd358c0ee5a1c6406afd2c11">ALPAKA_DECAY_T</a>(TArgs)&gt; <span class="keyword">const</span>&amp;... args) {</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                        <span class="keywordflow">return</span> getBlockSharedMemDynSizeBytes&lt;TAcc&gt;(</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;                            task.m_kernelFnObj,</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;                            blockThreadExtent,</div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;                            threadElemExtent,</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;                            args...);</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                    },</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160; </div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;                <span class="comment">// Log the block shared memory idx.</span></div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; BlockSharedMemDynSizeBytes: &quot;</span> &lt;&lt; blockSharedMemDynSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;                          &lt;&lt; std::endl;</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160; </div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;                <span class="keyword">auto</span> kernelName = alpaka::detail::</div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;                    gpuKernel&lt;TKernelFnObj, TApi, TAcc, TDim, TIdx, remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;&gt;...&gt;;</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;                <span class="comment">// Log the function attributes.</span></div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;                <span class="keyword">typename</span> TApi::FuncAttributes_t funcAttrs;</div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;                TApi::funcGetAttributes(&amp;funcAttrs, kernelName);</div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; binaryVersion: &quot;</span> &lt;&lt; funcAttrs.binaryVersion</div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; constSizeBytes: &quot;</span> &lt;&lt; funcAttrs.constSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; localSizeBytes: &quot;</span> &lt;&lt; funcAttrs.localSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; maxThreadsPerBlock: &quot;</span> &lt;&lt; funcAttrs.maxThreadsPerBlock</div>
<div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; numRegs: &quot;</span> &lt;&lt; funcAttrs.numRegs &lt;&lt; <span class="stringliteral">&quot; ptxVersion: &quot;</span> &lt;&lt; funcAttrs.ptxVersion</div>
<div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; sharedSizeBytes: &quot;</span> &lt;&lt; funcAttrs.sharedSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160; </div>
<div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;                <span class="comment">// Set the current device.</span></div>
<div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;                <a class="code" href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a>(TApi::setDevice(queue.m_spQueueImpl-&gt;m_dev.getNativeHandle()));</div>
<div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160; </div>
<div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;                <span class="comment">// Enqueue the kernel execution.</span></div>
<div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;                <a class="code" href="namespacealpaka_1_1core.html#a3bc48ef7c999409550fcbe1a948d6f31">std::apply</a>(</div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;<a class="code" href="Decay_8hpp.html#afba6dfdddd358c0ee5a1c6406afd2c11">ALPAKA_DECAY_T</a>(TArgs)&gt; <span class="keyword">const</span>&amp;... args)</div>
<div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                    {</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;                        kernelName&lt;&lt;&lt;</div>
<div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;                            gridDim,</div>
<div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;                            blockDim,</div>
<div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;                            <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(blockSharedMemDynSizeBytes),</div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;                            queue.getNativeHandle()&gt;&gt;&gt;(threadElemExtent, task.m_kernelFnObj, args...);</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;                    },</div>
<div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160; </div>
<div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;                <span class="comment">// Wait for the kernel execution to finish but do not check error return of this call.</span></div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;                <span class="comment">// Do not use the alpaka::wait method because it checks the error itself but we want to give a custom</span></div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;                <span class="comment">// error message.</span></div>
<div class="line"><a name="l00396"></a><span class="lineno">  396</span>&#160;                std::ignore = TApi::streamSynchronize(queue.getNativeHandle());</div>
<div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;                <span class="keywordflow">if</span> constexpr(<a class="code" href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a> &gt;= <a class="code" href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a>)</div>
<div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;                {</div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;                    <span class="keyword">auto</span> <span class="keyword">const</span> msg</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;                        = std::string{<span class="stringliteral">&quot;&#39;execution of kernel: &#39;&quot;</span> + core::demangled&lt;TKernelFnObj&gt; + <span class="stringliteral">&quot;&#39; failed with&quot;</span>};</div>
<div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;                    ::alpaka::uniform_cuda_hip::detail::rtCheckLastError&lt;TApi, true&gt;(msg.c_str(), __FILE__, __LINE__);</div>
<div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;                }</div>
<div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;            }</div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;        };</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;    } <span class="comment">// namespace trait</span></div>
<div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;} <span class="comment">// namespace alpaka</span></div>
<div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160; </div>
<div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;<span class="preprocessor">#    endif</span></div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160; </div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="ttc" id="aAccGpuUniformCudaHipRt_8hpp_html"><div class="ttname"><a href="AccGpuUniformCudaHipRt_8hpp.html">AccGpuUniformCudaHipRt.hpp</a></div></div>
<div class="ttc" id="aBoostPredef_8hpp_html"><div class="ttname"><a href="BoostPredef_8hpp.html">BoostPredef.hpp</a></div></div>
<div class="ttc" id="aCuda_8hpp_html"><div class="ttname"><a href="Cuda_8hpp.html">Cuda.hpp</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_a6a8e5f5a48b0bff7946528ab4e3e9f62"><div class="ttname"><a href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a></div><div class="ttdeci">#define ALPAKA_DEBUG_MINIMAL</div><div class="ttdoc">The minimal debug level.</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00021">Debug.hpp:21</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_a7f84384a17e301a636770e17c2951383"><div class="ttname"><a href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a></div><div class="ttdeci">#define ALPAKA_DEBUG</div><div class="ttdoc">Set the minimum log level if it is not defined.</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00027">Debug.hpp:27</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_ac556c317f934c69c8c8c083c5068f681"><div class="ttname"><a href="Debug_8hpp.html#ac556c317f934c69c8c8c083c5068f681">ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</a></div><div class="ttdeci">#define ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00058">Debug.hpp:58</a></div></div>
<div class="ttc" id="aDecay_8hpp_html"><div class="ttname"><a href="Decay_8hpp.html">Decay.hpp</a></div></div>
<div class="ttc" id="aDecay_8hpp_html_afba6dfdddd358c0ee5a1c6406afd2c11"><div class="ttname"><a href="Decay_8hpp.html#afba6dfdddd358c0ee5a1c6406afd2c11">ALPAKA_DECAY_T</a></div><div class="ttdeci">#define ALPAKA_DECAY_T(Type)</div><div class="ttdoc">Wrapper around std::decay_t for parameter pack expansion expressions.</div><div class="ttdef"><b>Definition:</b> <a href="Decay_8hpp_source.html#l00030">Decay.hpp:30</a></div></div>
<div class="ttc" id="aDemangleTypeNames_8hpp_html"><div class="ttname"><a href="DemangleTypeNames_8hpp.html">DemangleTypeNames.hpp</a></div></div>
<div class="ttc" id="aDevUniformCudaHipRt_8hpp_html"><div class="ttname"><a href="DevUniformCudaHipRt_8hpp.html">DevUniformCudaHipRt.hpp</a></div></div>
<div class="ttc" id="aHip_8hpp_html"><div class="ttname"><a href="Hip_8hpp.html">Hip.hpp</a></div></div>
<div class="ttc" id="aQueueUniformCudaHipRtBlocking_8hpp_html"><div class="ttname"><a href="QueueUniformCudaHipRtBlocking_8hpp.html">QueueUniformCudaHipRtBlocking.hpp</a></div></div>
<div class="ttc" id="aQueueUniformCudaHipRtNonBlocking_8hpp_html"><div class="ttname"><a href="QueueUniformCudaHipRtNonBlocking_8hpp.html">QueueUniformCudaHipRtNonBlocking.hpp</a></div></div>
<div class="ttc" id="aRemoveRestrict_8hpp_html"><div class="ttname"><a href="RemoveRestrict_8hpp.html">RemoveRestrict.hpp</a></div></div>
<div class="ttc" id="aUniformCudaHip_8hpp_html_aad1e1de5a82a5f770453aed02324a99f"><div class="ttname"><a href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a></div><div class="ttdeci">#define ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK(cmd)</div><div class="ttdoc">CUDA/HIP runtime error checking with log and exception.</div><div class="ttdef"><b>Definition:</b> <a href="UniformCudaHip_8hpp_source.html#l00126">UniformCudaHip.hpp:126</a></div></div>
<div class="ttc" id="aWorkDivHelpers_8hpp_html"><div class="ttname"><a href="WorkDivHelpers_8hpp.html">WorkDivHelpers.hpp</a></div></div>
<div class="ttc" id="aWorkDivMembers_8hpp_html"><div class="ttname"><a href="WorkDivMembers_8hpp.html">WorkDivMembers.hpp</a></div></div>
<div class="ttc" id="aacc_2Traits_8hpp_html"><div class="ttname"><a href="acc_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aclassalpaka_1_1AccGpuUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1AccGpuUniformCudaHipRt.html">alpaka::AccGpuUniformCudaHipRt</a></div><div class="ttdoc">The GPU CUDA accelerator.</div><div class="ttdef"><b>Definition:</b> <a href="AccGpuUniformCudaHipRt_8hpp_source.html#l00057">AccGpuUniformCudaHipRt.hpp:75</a></div></div>
<div class="ttc" id="aclassalpaka_1_1DevUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1DevUniformCudaHipRt.html">alpaka::DevUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT device handle.</div><div class="ttdef"><b>Definition:</b> <a href="DevUniformCudaHipRt_8hpp_source.html#l00062">DevUniformCudaHipRt.hpp:65</a></div></div>
<div class="ttc" id="aclassalpaka_1_1PltfUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1PltfUniformCudaHipRt.html">alpaka::PltfUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT platform.</div><div class="ttdef"><b>Definition:</b> <a href="PltfUniformCudaHipRt_8hpp_source.html#l00033">PltfUniformCudaHipRt.hpp:34</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">alpaka::TaskKernelGpuUniformCudaHipRt</a></div><div class="ttdoc">The GPU CUDA/HIP accelerator execution task.</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00137">TaskKernelGpuUniformCudaHipRt.hpp:138</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a35fc3725cde6251430e0930d4a8ee681"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">alpaka::TaskKernelGpuUniformCudaHipRt::m_kernelFnObj</a></div><div class="ttdeci">TKernelFnObj m_kernelFnObj</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00154">TaskKernelGpuUniformCudaHipRt.hpp:154</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a81cbbfab8168bd34880ce326a25d83aa"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">alpaka::TaskKernelGpuUniformCudaHipRt::m_args</a></div><div class="ttdeci">std::tuple&lt; remove_restrict_t&lt; std::decay_t&lt; TArgs &gt; &gt;... &gt; m_args</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00155">TaskKernelGpuUniformCudaHipRt.hpp:155</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a8670d9407b302e594f922885e5b9d1e9"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">alpaka::TaskKernelGpuUniformCudaHipRt::TaskKernelGpuUniformCudaHipRt</a></div><div class="ttdeci">ALPAKA_FN_HOST TaskKernelGpuUniformCudaHipRt(TWorkDiv &amp;&amp;workDiv, TKernelFnObj const &amp;kernelFnObj, TArgs &amp;&amp;... args)</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00141">TaskKernelGpuUniformCudaHipRt.hpp:141</a></div></div>
<div class="ttc" id="aclassalpaka_1_1Vec_html"><div class="ttname"><a href="classalpaka_1_1Vec.html">alpaka::Vec&lt; TDim, TIdx &gt;</a></div></div>
<div class="ttc" id="aclassalpaka_1_1WorkDivMembers_html"><div class="ttname"><a href="classalpaka_1_1WorkDivMembers.html">alpaka::WorkDivMembers</a></div><div class="ttdoc">A basic class holding the work division as grid block extent, block thread and thread element extent.</div><div class="ttdef"><b>Definition:</b> <a href="WorkDivMembers_8hpp_source.html#l00023">WorkDivMembers.hpp:24</a></div></div>
<div class="ttc" id="aclassalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">alpaka::uniform_cuda_hip::detail::QueueUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT queue.</div><div class="ttdef"><b>Definition:</b> <a href="QueueUniformCudaHipRt_8hpp_source.html#l00099">QueueUniformCudaHipRt.hpp:103</a></div></div>
<div class="ttc" id="acore_2Common_8hpp_html_a30cf38ce8c63908b355f69eb893da575"><div class="ttname"><a href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a></div><div class="ttdeci">#define ALPAKA_FN_HOST</div><div class="ttdef"><b>Definition:</b> <a href="core_2Common_8hpp_source.html#l00037">Common.hpp:37</a></div></div>
<div class="ttc" id="adev_2Traits_8hpp_html"><div class="ttname"><a href="dev_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="adim_2Traits_8hpp_html"><div class="ttname"><a href="dim_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aidx_2Traits_8hpp_html"><div class="ttname"><a href="idx_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="akernel_2Traits_8hpp_html"><div class="ttname"><a href="kernel_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1core_html_a3bc48ef7c999409550fcbe1a948d6f31"><div class="ttname"><a href="namespacealpaka_1_1core.html#a3bc48ef7c999409550fcbe1a948d6f31">alpaka::core::apply</a></div><div class="ttdeci">constexpr auto apply(TFunc &amp;&amp;f, Tuple&lt; TArgs... &gt; t)</div><div class="ttdef"><b>Definition:</b> <a href="Tuple_8hpp_source.html#l00031">Tuple.hpp:31</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1detail_html_a64053dbfaaaefdf2572ec83b38b30623"><div class="ttname"><a href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">alpaka::detail::gpuKernel</a></div><div class="ttdeci">__global__ void gpuKernel(Vec&lt; TDim, TIdx &gt; const threadElemExtent, TKernelFnObj const kernelFnObj, TArgs... args)</div><div class="ttdoc">The GPU CUDA/HIP kernel entry point.</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00077">TaskKernelGpuUniformCudaHipRt.hpp:77</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1math_html_ad1a3c72853dc08a5e54e532f25a08988"><div class="ttname"><a href="namespacealpaka_1_1math.html#ad1a3c72853dc08a5e54e532f25a08988">alpaka::math::min</a></div><div class="ttdeci">ALPAKA_NO_HOST_ACC_WARNING ALPAKA_FN_HOST_ACC auto min(T const &amp;min_ctx, Tx const &amp;x, Ty const &amp;y)</div><div class="ttdoc">Returns the smaller of two arguments. NaNs are treated as missing data (between a NaN and a numeric v...</div><div class="ttdef"><b>Definition:</b> <a href="math_2Traits_8hpp_source.html#l01143">Traits.hpp:1143</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1uniform__cuda__hip_1_1detail_html_a552124cfd6ee8654baa53bc1710c0974"><div class="ttname"><a href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">alpaka::uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a></div><div class="ttdeci">ALPAKA_FN_HOST auto convertVecToUniformCudaHipDim(Vec&lt; TDim, TIdx &gt; const &amp;vec) -&gt; dim3</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00120">TaskKernelGpuUniformCudaHipRt.hpp:120</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1uniform__cuda__hip_1_1detail_html_af9741bdf6dda9699e1dd8ca18d81d16a"><div class="ttname"><a href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">alpaka::uniform_cuda_hip::detail::checkVecOnly3Dim</a></div><div class="ttdeci">ALPAKA_FN_HOST auto checkVecOnly3Dim(Vec&lt; TDim, TIdx &gt; const &amp;vec) -&gt; void</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00103">TaskKernelGpuUniformCudaHipRt.hpp:103</a></div></div>
<div class="ttc" id="anamespacealpaka_html"><div class="ttname"><a href="namespacealpaka.html">alpaka</a></div><div class="ttdoc">The alpaka accelerator library.</div><div class="ttdef"><b>Definition:</b> <a href="AccCpuOmp2Blocks_8hpp_source.html#l00051">AccCpuOmp2Blocks.hpp:52</a></div></div>
<div class="ttc" id="anamespacealpaka_html_a78675a272ead29bbbf706b20727fa209"><div class="ttname"><a href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">alpaka::remove_restrict_t</a></div><div class="ttdeci">typename remove_restrict&lt; T &gt;::type remove_restrict_t</div><div class="ttdoc">Helper to remove restrict from a type.</div><div class="ttdef"><b>Definition:</b> <a href="RemoveRestrict_8hpp_source.html#l00039">RemoveRestrict.hpp:39</a></div></div>
<div class="ttc" id="anamespacealpaka_html_aa4fe5980725182b3306caf3167053a75"><div class="ttname"><a href="namespacealpaka.html#aa4fe5980725182b3306caf3167053a75">alpaka::getDev</a></div><div class="ttdeci">ALPAKA_FN_HOST auto getDev(T const &amp;t)</div><div class="ttdef"><b>Definition:</b> <a href="dev_2Traits_8hpp_source.html#l00063">Traits.hpp:63</a></div></div>
<div class="ttc" id="anamespacealpaka_html_ac49b3c4b09c8a7455e8f88faa51484df"><div class="ttname"><a href="namespacealpaka.html#ac49b3c4b09c8a7455e8f88faa51484df">alpaka::getAccName</a></div><div class="ttdeci">ALPAKA_FN_HOST auto getAccName() -&gt; std::string</div><div class="ttdef"><b>Definition:</b> <a href="acc_2Traits_8hpp_source.html#l00072">Traits.hpp:72</a></div></div>
<div class="ttc" id="anamespacealpaka_html_aee3fb80b82e8f3e9601195afb0b8c34c"><div class="ttname"><a href="namespacealpaka.html#aee3fb80b82e8f3e9601195afb0b8c34c">alpaka::Dim</a></div><div class="ttdeci">typename trait::DimType&lt; T &gt;::type Dim</div><div class="ttdoc">The dimension type trait alias template to remove the ::type.</div><div class="ttdef"><b>Definition:</b> <a href="dim_2Traits_8hpp_source.html#l00024">Traits.hpp:24</a></div></div>
<div class="ttc" id="apltf_2Traits_8hpp_html"><div class="ttname"><a href="pltf_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aqueue_2Traits_8hpp_html"><div class="ttname"><a href="queue_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1AccType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1AccType.html">alpaka::trait::AccType</a></div><div class="ttdoc">The accelerator type trait.</div><div class="ttdef"><b>Definition:</b> <a href="acc_2Traits_8hpp_source.html#l00037">Traits.hpp:37</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DevType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1DevType.html">alpaka::trait::DevType</a></div><div class="ttdoc">The device type trait.</div><div class="ttdef"><b>Definition:</b> <a href="dev_2Traits_8hpp_source.html#l00026">Traits.hpp:26</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1_html_ad31779fde1a2b8cf69e2e330b969d07a"><div class="ttname"><a href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">alpaka::trait::DimType&lt; TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::type</a></div><div class="ttdeci">TDim type</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00178">TaskKernelGpuUniformCudaHipRt.hpp:178</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DimType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1DimType.html">alpaka::trait::DimType</a></div><div class="ttdoc">The dimension getter type trait.</div><div class="ttdef"><b>Definition:</b> <a href="dim_2Traits_8hpp_source.html#l00019">Traits.hpp:19</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtBlocking_3_01TApi_01_4_00_01TaskKernelc6360c0fc744d397d00b5014e3524b9c_html_a148631736adb9a133a5db69d73bdf8c1"><div class="ttname"><a href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtBlocking_3_01TApi_01_4_00_01TaskKernelc6360c0fc744d397d00b5014e3524b9c.html#a148631736adb9a133a5db69d73bdf8c1">alpaka::trait::Enqueue&lt; QueueUniformCudaHipRtBlocking&lt; TApi &gt;, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::enqueue</a></div><div class="ttdeci">static ALPAKA_FN_HOST auto enqueue(QueueUniformCudaHipRtBlocking&lt; TApi &gt; &amp;queue, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; const &amp;task) -&gt; void</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00308">TaskKernelGpuUniformCudaHipRt.hpp:308</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtNonBlocking_3_01TApi_01_4_00_01TaskKercda831e3343a928a98cd81e7d01f0f88_html_a4baf425759162472813f919548823adb"><div class="ttname"><a href="structalpaka_1_1trait_1_1Enqueue_3_01QueueUniformCudaHipRtNonBlocking_3_01TApi_01_4_00_01TaskKercda831e3343a928a98cd81e7d01f0f88.html#a4baf425759162472813f919548823adb">alpaka::trait::Enqueue&lt; QueueUniformCudaHipRtNonBlocking&lt; TApi &gt;, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::enqueue</a></div><div class="ttdeci">static ALPAKA_FN_HOST auto enqueue(QueueUniformCudaHipRtNonBlocking&lt; TApi &gt; &amp;queue, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; const &amp;task) -&gt; void</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00201">TaskKernelGpuUniformCudaHipRt.hpp:201</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1Enqueue_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1Enqueue.html">alpaka::trait::Enqueue</a></div><div class="ttdoc">The queue enqueue trait.</div><div class="ttdef"><b>Definition:</b> <a href="queue_2Traits_8hpp_source.html#l00028">Traits.hpp:28</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1IdxType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1IdxType.html">alpaka::trait::IdxType</a></div><div class="ttdoc">The idx type trait.</div><div class="ttdef"><b>Definition:</b> <a href="idx_2Traits_8hpp_source.html#l00029">Traits.hpp:29</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1PltfType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1PltfType.html">alpaka::trait::PltfType</a></div><div class="ttdoc">The platform type trait.</div><div class="ttdef"><b>Definition:</b> <a href="pltf_2Traits_8hpp_source.html#l00031">Traits.hpp:31</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1TIdx_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1TIdx.html">alpaka::trait::TIdx</a></div><div class="ttdoc">The ViewPlainPtr memory pitch get trait specialization.</div><div class="ttdef"><b>Definition:</b> <a href="ViewPlainPtr_8hpp_source.html#l00142">ViewPlainPtr.hpp:146</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_f712bff28b6ff1ff870a222047d04675.html">alpaka</a></li><li class="navelem"><a class="el" href="dir_ddf4b6b668da48004ea34c8205023599.html">kernel</a></li><li class="navelem"><a class="el" href="TaskKernelGpuUniformCudaHipRt_8hpp.html">TaskKernelGpuUniformCudaHipRt.hpp</a></li>
    <li class="footer">Generated on Wed Jan 11 2023 17:30:23 for alpaka by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
