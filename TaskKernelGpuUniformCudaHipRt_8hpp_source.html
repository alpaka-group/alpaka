<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>alpaka: /home/runner/work/alpaka/alpaka/include/alpaka/kernel/TaskKernelGpuUniformCudaHipRt.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="alpaka_doxygen.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">alpaka
   </div>
   <div id="projectbrief">Abstraction Library for Parallel Kernel Acceleration</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('TaskKernelGpuUniformCudaHipRt_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">TaskKernelGpuUniformCudaHipRt.hpp</div>  </div>
</div><!--header-->
<div class="contents">
<a href="TaskKernelGpuUniformCudaHipRt_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/* Copyright 2024 Benjamin Worpitz, Erik Zenker, Matthias Werner, Ren√© Widera, Jan Stephan, Andrea Bocci, Bernhard</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * Manfred Gruber, Antonio Di Pilato, Mehmet Yusufoglu</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> * SPDX-License-Identifier: MPL-2.0</span></div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> */</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160; </div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#pragma once</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160; </div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="AccGpuUniformCudaHipRt_8hpp.html">alpaka/acc/AccGpuUniformCudaHipRt.hpp</a>&quot;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="acc_2Traits_8hpp.html">alpaka/acc/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="BoostPredef_8hpp.html">alpaka/core/BoostPredef.hpp</a>&quot;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Cuda_8hpp.html">alpaka/core/Cuda.hpp</a>&quot;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Decay_8hpp.html">alpaka/core/Decay.hpp</a>&quot;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="DemangleTypeNames_8hpp.html">alpaka/core/DemangleTypeNames.hpp</a>&quot;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="Hip_8hpp.html">alpaka/core/Hip.hpp</a>&quot;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="RemoveRestrict_8hpp.html">alpaka/core/RemoveRestrict.hpp</a>&quot;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="DevUniformCudaHipRt_8hpp.html">alpaka/dev/DevUniformCudaHipRt.hpp</a>&quot;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="dev_2Traits_8hpp.html">alpaka/dev/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="dim_2Traits_8hpp.html">alpaka/dim/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="idx_2Traits_8hpp.html">alpaka/idx/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="KernelFunctionAttributes_8hpp.html">alpaka/kernel/KernelFunctionAttributes.hpp</a>&quot;</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="kernel_2Traits_8hpp.html">alpaka/kernel/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="platform_2Traits_8hpp.html">alpaka/platform/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="queue_2Traits_8hpp.html">alpaka/queue/Traits.hpp</a>&quot;</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="QueueUniformCudaHipRt_8hpp.html">alpaka/queue/cuda_hip/QueueUniformCudaHipRt.hpp</a>&quot;</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="WorkDivHelpers_8hpp.html">alpaka/workdiv/WorkDivHelpers.hpp</a>&quot;</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="WorkDivMembers_8hpp.html">alpaka/workdiv/WorkDivMembers.hpp</a>&quot;</span></div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160; </div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &lt;tuple&gt;</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &lt;type_traits&gt;</span></div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="preprocessor">#    include &lt;iostream&gt;</span></div>
<div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160; </div>
<div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#if defined(ALPAKA_ACC_GPU_CUDA_ENABLED) || defined(ALPAKA_ACC_GPU_HIP_ENABLED)</span></div>
<div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160; </div>
<div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="preprocessor">#    if !defined(ALPAKA_HOST_ONLY)</span></div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160; </div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="preprocessor">#        include &quot;<a class="code" href="BoostPredef_8hpp.html">alpaka/core/BoostPredef.hpp</a>&quot;</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160; </div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="preprocessor">#        if defined(ALPAKA_ACC_GPU_CUDA_ENABLED) &amp;&amp; !BOOST_LANG_CUDA</span></div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="preprocessor">#            error If ALPAKA_ACC_GPU_CUDA_ENABLED is set, the compiler has to support CUDA!</span></div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160; </div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;<span class="preprocessor">#        if defined(ALPAKA_ACC_GPU_HIP_ENABLED) &amp;&amp; !BOOST_LANG_HIP</span></div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;<span class="preprocessor">#            error If ALPAKA_ACC_GPU_HIP_ENABLED is set, the compiler has to support HIP!</span></div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160; </div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacealpaka.html">alpaka</a></div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;{</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="keyword">namespace </span>detail</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;    {</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;<span class="preprocessor">#        if BOOST_COMP_CLANG</span></div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="preprocessor">#            pragma clang diagnostic push</span></div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;<span class="preprocessor">#            pragma clang diagnostic ignored &quot;-Wunused-template&quot;</span></div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;<span class="preprocessor">#        endif</span><span class="comment"></span></div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;<span class="comment">        //! The GPU CUDA/HIP kernel entry point.</span></div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;<span class="comment"></span>        <span class="comment">// \NOTE: &#39;A __global__ function or function template cannot have a trailing return type.&#39;</span></div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;        <span class="comment">// We have put the function into a shallow namespace and gave it a short name, so the mangled name in the</span></div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;        <span class="comment">// profiler (e.g. ncu) is as shorter as possible.</span></div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00062"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">   62</a></span>&#160;        __global__ <span class="keywordtype">void</span> <a class="code" href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">gpuKernel</a>(</div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;            <a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span> threadElemExtent,</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;            TKernelFnObj <span class="keyword">const</span> kernelFnObj,</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;            TArgs... args)</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;        {</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;            TAcc <span class="keyword">const</span> acc(threadElemExtent);</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160; </div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="comment">// with clang it is not possible to query std::result_of for a pure device lambda created on the host side</span></div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;<span class="preprocessor">#        if !(BOOST_COMP_CLANG_CUDA &amp;&amp; BOOST_COMP_CLANG)</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;            static_assert(</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;                std::is_same_v&lt;decltype(kernelFnObj(<span class="keyword">const_cast&lt;</span>TAcc const&amp;<span class="keyword">&gt;</span>(acc), args...)), <span class="keywordtype">void</span>&gt;,</div>
<div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;                <span class="stringliteral">&quot;The TKernelFnObj is required to return void!&quot;</span>);</div>
<div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;            kernelFnObj(<span class="keyword">const_cast&lt;</span>TAcc const&amp;<span class="keyword">&gt;</span>(acc), args...);</div>
<div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        }</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;<span class="preprocessor">#        if BOOST_COMP_CLANG</span></div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;<span class="preprocessor">#            pragma clang diagnostic pop</span></div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    } <span class="comment">// namespace detail</span></div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160; </div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keyword">namespace </span>uniform_cuda_hip</div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;    {</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;        <span class="keyword">namespace </span>detail</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;        {</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;            <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx&gt;</div>
<div class="line"><a name="l00087"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">   87</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">auto</span> <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">checkVecOnly3Dim</a>(<a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span>&amp; vec) -&gt; <span class="keywordtype">void</span></div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;            {</div>
<div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt; 0)</div>
<div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                {</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;                    <span class="keywordflow">for</span>(<span class="keyword">auto</span> i = <a class="code" href="namespacealpaka_1_1math.html#ad1a3c72853dc08a5e54e532f25a08988">std::min</a>(<span class="keyword">typename</span> TDim::value_type{3}, TDim::value); i &lt; TDim::value; ++i)</div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;                    {</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;                        <span class="keywordflow">if</span>(vec[TDim::value - 1u - i] != 1)</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;                        {</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;                            <span class="keywordflow">throw</span> std::runtime_error(</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                                <span class="stringliteral">&quot;The CUDA/HIP accelerator supports a maximum of 3 dimensions. All &quot;</span></div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                                <span class="stringliteral">&quot;work division extents of the dimensions higher 3 have to be 1!&quot;</span>);</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;                        }</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;                    }</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;                }</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;            }</div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160; </div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;            <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx&gt;</div>
<div class="line"><a name="l00104"></a><span class="lineno"><a class="line" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">  104</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">auto</span> <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">convertVecToUniformCudaHipDim</a>(<a class="code" href="classalpaka_1_1Vec.html">Vec&lt;TDim, TIdx&gt;</a> <span class="keyword">const</span>&amp; vec) -&gt; dim3</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;            {</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;                dim3 dim(1, 1, 1);</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 1)</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                    dim.x = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 1u]);</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 2)</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;                    dim.y = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 2u]);</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;                <span class="keywordflow">if</span> constexpr(TDim::value &gt;= 3)</div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;                    dim.z = <span class="keyword">static_cast&lt;</span><span class="keywordtype">unsigned</span><span class="keyword">&gt;</span>(vec[TDim::value - 3u]);</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;                <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">checkVecOnly3Dim</a>(vec);</div>
<div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;                <span class="keywordflow">return</span> dim;</div>
<div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;            }</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;        } <span class="comment">// namespace detail</span></div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    } <span class="comment">// namespace uniform_cuda_hip</span></div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;<span class="comment">    //! The GPU CUDA/HIP accelerator execution task.</span></div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;<span class="comment"></span>    <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00121"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">  121</a></span>&#160;    <span class="keyword">class </span><a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a> final : <span class="keyword">public</span> <a class="code" href="classalpaka_1_1WorkDivMembers.html">WorkDivMembers</a>&lt;TDim, TIdx&gt;</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    {</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;    <span class="keyword">public</span>:</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TWorkDiv&gt;</div>
<div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">  125</a></span>&#160;        <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">TaskKernelGpuUniformCudaHipRt</a>(</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;            TWorkDiv&amp;&amp; workDiv,</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;            TKernelFnObj <span class="keyword">const</span>&amp; kernelFnObj,</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;            TArgs&amp;&amp;... args)</div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;            : <a class="code" href="classalpaka_1_1WorkDivMembers.html">WorkDivMembers</a>&lt;TDim, TIdx&gt;(std::forward&lt;TWorkDiv&gt;(workDiv))</div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;            , <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">m_kernelFnObj</a>(kernelFnObj)</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;            , <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">m_args</a>(std::forward&lt;TArgs&gt;(args)...)</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;        {</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;            static_assert(</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;                <a class="code" href="namespacealpaka.html#aee3fb80b82e8f3e9601195afb0b8c34c">Dim</a>&lt;std::decay_t&lt;TWorkDiv&gt;&gt;::value == TDim::value,</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;                <span class="stringliteral">&quot;The work division and the execution task have to be of the same dimensionality!&quot;</span>);</div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;        }</div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160; </div>
<div class="line"><a name="l00138"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">  138</a></span>&#160;        TKernelFnObj <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">m_kernelFnObj</a>;</div>
<div class="line"><a name="l00139"></a><span class="lineno"><a class="line" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">  139</a></span>&#160;        std::tuple&lt;remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;&gt;...&gt; <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">m_args</a>;</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    };</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160; </div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    <span class="keyword">namespace </span>trait</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    {<span class="comment"></span></div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task accelerator type trait specialization.</span></div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00146"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1AccType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_b7d5109d450cd376a8ec278df7986307.html">  146</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1AccType.html">AccType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;        {</div>
<div class="line"><a name="l00148"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1AccType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_b7d5109d450cd376a8ec278df7986307.html#af939da8626ba47432a68e612435b3f7f">  148</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">type</a> = <a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>;</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;        };</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task device type trait specialization.</span></div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00153"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DevType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_748136d18cba1bf097b4b40671af9556.html">  153</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1DevType.html">DevType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;        {</div>
<div class="line"><a name="l00155"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DevType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_748136d18cba1bf097b4b40671af9556.html#ac6bd4bc93360150aeefee20bdd24e5ae">  155</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="classalpaka_1_1DevUniformCudaHipRt.html">type</a> = <a class="code" href="classalpaka_1_1DevUniformCudaHipRt.html">DevUniformCudaHipRt&lt;TApi&gt;</a>;</div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;        };</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task dimension getter trait specialization.</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00160"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html">  160</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1DimType.html">DimType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        {</div>
<div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">  162</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">type</a> = TDim;</div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        };</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;<span class="comment">        //! The CPU CUDA/HIP execution task platform type trait specialization.</span></div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1PlatformType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_010d3ab9faa5359f76890af49d5bc67568.html">  167</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1PlatformType.html">PlatformType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;        {</div>
<div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1PlatformType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_010d3ab9faa5359f76890af49d5bc67568.html#a9f29be5c7f2b5b7a6072f9710d4b54b3">  169</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="structalpaka_1_1PlatformUniformCudaHipRt.html">type</a> = <a class="code" href="structalpaka_1_1PlatformUniformCudaHipRt.html">PlatformUniformCudaHipRt&lt;TApi&gt;</a>;</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;        };</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="comment">        //! The GPU CUDA/HIP execution task idx type trait specialization.</span></div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TAcc, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFnObj, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00174"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html">  174</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1IdxType.html">IdxType</a>&lt;<a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;        {</div>
<div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html#a3661e7ff93f5ec2d0b6929c6a790f564">  176</a></span>&#160;            <span class="keyword">using</span> <a class="code" href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html#a3661e7ff93f5ec2d0b6929c6a790f564">type</a> = TIdx;</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;        };</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;<span class="comment">        //! The CUDA/HIP kernel enqueue trait specialization.</span></div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;            <span class="keyword">typename</span> TApi,</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;            <span class="keywordtype">bool</span> TBlocking,</div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;            <span class="keyword">typename</span> TAcc,</div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;            <span class="keyword">typename</span> TDim,</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;            <span class="keyword">typename</span> TIdx,</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;            <span class="keyword">typename</span> TKernelFnObj,</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;            <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00188"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_3_01Tcf5f0cfca5b539ecd63517c701535324.html">  188</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1Enqueue.html">Enqueue</a>&lt;</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;            uniform_cuda_hip::detail::QueueUniformCudaHipRt&lt;TApi, TBlocking&gt;,</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;            <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt</a>&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;&gt;</div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;        {</div>
<div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1Enqueue_3_01uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_3_01Tcf5f0cfca5b539ecd63517c701535324.html#add361fe22454f8fb779829af220da54c">  192</a></span>&#160;            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">static</span> <span class="keyword">auto</span> <a class="code" href="structalpaka_1_1trait_1_1Enqueue_3_01uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_3_01Tcf5f0cfca5b539ecd63517c701535324.html#add361fe22454f8fb779829af220da54c">enqueue</a>(</div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;                <a class="code" href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">uniform_cuda_hip::detail::QueueUniformCudaHipRt&lt;TApi, TBlocking&gt;</a>&amp; queue,</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;                <a class="code" href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">TaskKernelGpuUniformCudaHipRt&lt;TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs...&gt;</a> <span class="keyword">const</span>&amp; task) -&gt; <span class="keywordtype">void</span></div>
<div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;            {</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;                <a class="code" href="Debug_8hpp.html#ac556c317f934c69c8c8c083c5068f681">ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</a>;</div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;                <span class="comment">// TODO: Check that (sizeof(TKernelFnObj) * m_3uiBlockThreadExtent.prod()) &lt; available memory idx</span></div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160; </div>
<div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;                <span class="comment">// std::size_t printfFifoSize;</span></div>
<div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot; INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;                <span class="comment">// TApi::deviceSetLimit(TApi::limitPrintfFifoSize, printfFifoSize*10);</span></div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;                <span class="comment">// TApi::deviceGetLimit(&amp;printfFifoSize, TApi::limitPrintfFifoSize);</span></div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;                <span class="comment">// std::cout &lt;&lt; __func__ &lt;&lt; &quot; INFO: printfFifoSize: &quot; &lt;&lt; printfFifoSize &lt;&lt; std::endl;</span></div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> gridBlockExtent = getWorkDiv&lt;Grid, Blocks&gt;(task);</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockThreadExtent = getWorkDiv&lt;Block, Threads&gt;(task);</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> threadElemExtent = getWorkDiv&lt;Thread, Elems&gt;(task);</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160; </div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                dim3 <span class="keyword">const</span> gridDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(gridBlockExtent);</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;                dim3 <span class="keyword">const</span> blockDim = <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a>(blockThreadExtent);</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                <a class="code" href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">uniform_cuda_hip::detail::checkVecOnly3Dim</a>(threadElemExtent);</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160; </div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; gridDim: (&quot;</span> &lt;&lt; gridDim.z &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; gridDim.y &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; gridDim.x &lt;&lt; <span class="stringliteral">&quot;)\n&quot;</span>;</div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; blockDim: (&quot;</span> &lt;&lt; blockDim.z &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; blockDim.y &lt;&lt; <span class="stringliteral">&quot;, &quot;</span> &lt;&lt; blockDim.x</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot;)\n&quot;</span>;</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160; </div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_MINIMAL</span></div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                <span class="comment">// This checks for a valid work division that is also compliant with the hardware maxima of the</span></div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                <span class="comment">// accelerator.</span></div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;                <span class="keywordflow">if</span>(!isValidWorkDiv&lt;TAcc&gt;(task, <a class="code" href="namespacealpaka.html#aa4fe5980725182b3306caf3167053a75">getDev</a>(queue)))</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;                {</div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;                    <span class="keywordflow">throw</span> std::runtime_error(</div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;                        <span class="stringliteral">&quot;The given work division is not valid or not supported by the device of type &quot;</span></div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;                        + <a class="code" href="namespacealpaka.html#ac49b3c4b09c8a7455e8f88faa51484df">getAccName</a>&lt;<a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>&gt;() + <span class="stringliteral">&quot;!&quot;</span>);</div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;                }</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160; </div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;                <span class="comment">// Get the size of the block shared dynamic memory.</span></div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;                <span class="keyword">auto</span> <span class="keyword">const</span> blockSharedMemDynSizeBytes = std::apply(</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;std::decay_t&lt;TArgs&gt;&gt; <span class="keyword">const</span>&amp;... args) {</div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;                        <span class="keywordflow">return</span> getBlockSharedMemDynSizeBytes&lt;TAcc&gt;(</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;                            task.m_kernelFnObj,</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;                            blockThreadExtent,</div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;                            threadElemExtent,</div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                            args...);</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;                    },</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160; </div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;                <span class="comment">// Log the block shared memory idx.</span></div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; BlockSharedMemDynSizeBytes: &quot;</span> &lt;&lt; blockSharedMemDynSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;                          &lt;&lt; std::endl;</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160; </div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;                <span class="keyword">auto</span> kernelName = alpaka::detail::</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;                    gpuKernel&lt;TKernelFnObj, TApi, TAcc, TDim, TIdx, remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;&gt;...&gt;;</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160; </div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;                <span class="comment">// Log the function attributes.</span></div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;                <span class="keyword">typename</span> TApi::FuncAttributes_t funcAttrs;</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;                <a class="code" href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a>(TApi::funcGetAttributes(&amp;funcAttrs, kernelName));</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;                std::cout &lt;&lt; __func__ &lt;&lt; <span class="stringliteral">&quot; binaryVersion: &quot;</span> &lt;&lt; funcAttrs.binaryVersion</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; constSizeBytes: &quot;</span> &lt;&lt; funcAttrs.constSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; localSizeBytes: &quot;</span> &lt;&lt; funcAttrs.localSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span></div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; maxThreadsPerBlock: &quot;</span> &lt;&lt; funcAttrs.maxThreadsPerBlock</div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; numRegs: &quot;</span> &lt;&lt; funcAttrs.numRegs &lt;&lt; <span class="stringliteral">&quot; ptxVersion: &quot;</span> &lt;&lt; funcAttrs.ptxVersion</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;                          &lt;&lt; <span class="stringliteral">&quot; sharedSizeBytes: &quot;</span> &lt;&lt; funcAttrs.sharedSizeBytes &lt;&lt; <span class="stringliteral">&quot; B&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160; </div>
<div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;                <span class="comment">// Set the current device.</span></div>
<div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;                <a class="code" href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a>(TApi::setDevice(queue.m_spQueueImpl-&gt;m_dev.getNativeHandle()));</div>
<div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160; </div>
<div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;                <span class="comment">// Enqueue the kernel execution.</span></div>
<div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;                <span class="comment">// \NOTE: No const reference (const &amp;) is allowed as the parameter type because the kernel launch</span></div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;                <span class="comment">// language extension expects the arguments by value. This forces the type of a float argument given</span></div>
<div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;                <span class="comment">// with std::forward to this function to be of type float instead of e.g. &quot;float const &amp; __ptr64&quot;</span></div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;                <span class="comment">// (MSVC). If not given by value, the kernel launch code does not copy the value but the pointer to the</span></div>
<div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;                <span class="comment">// value location.</span></div>
<div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;                std::apply(</div>
<div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;                    [&amp;](<a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t</a>&lt;std::decay_t&lt;TArgs&gt;&gt; <span class="keyword">const</span>&amp;... args)</div>
<div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;                    {</div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;                        kernelName&lt;&lt;&lt;</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;                            gridDim,</div>
<div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;                            blockDim,</div>
<div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;                            <span class="keyword">static_cast&lt;</span>std::size_t<span class="keyword">&gt;</span>(blockSharedMemDynSizeBytes),</div>
<div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;                            queue.getNativeHandle()&gt;&gt;&gt;(threadElemExtent, task.m_kernelFnObj, args...);</div>
<div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;                    },</div>
<div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;                    task.m_args);</div>
<div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160; </div>
<div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                <span class="keywordflow">if</span> constexpr(TBlocking || <a class="code" href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a> &gt;= <a class="code" href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a>)</div>
<div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;                {</div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;                    <span class="comment">// Wait for the kernel execution to finish but do not check error return of this call.</span></div>
<div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                    <span class="comment">// Do not use the alpaka::wait method because it checks the error itself but we want to give a</span></div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;                    <span class="comment">// custom error message.</span></div>
<div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;                    std::ignore = TApi::streamSynchronize(queue.getNativeHandle());</div>
<div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;                }</div>
<div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;                <span class="keywordflow">if</span> constexpr(<a class="code" href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a> &gt;= <a class="code" href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a>)</div>
<div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;                {</div>
<div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;                    <span class="keyword">auto</span> <span class="keyword">const</span> msg</div>
<div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;                        = std::string{<span class="stringliteral">&quot;execution of kernel &#39;&quot;</span> + core::demangled&lt;TKernelFnObj&gt; + <span class="stringliteral">&quot;&#39; failed with&quot;</span>};</div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;                    ::alpaka::uniform_cuda_hip::detail::rtCheckLastError&lt;TApi, true&gt;(msg.c_str(), __FILE__, __LINE__);</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;                }</div>
<div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;            }</div>
<div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        };</div>
<div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;<span class="comment"></span> </div>
<div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;<span class="comment">        //! \brief Specialisation of the class template FunctionAttributes</span></div>
<div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;<span class="comment">        //! \tparam TApi The type the API of the GPU accelerator backend. Currently Cuda or Hip.</span></div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;<span class="comment">        //! \tparam TDim The dimensionality of the accelerator device properties.</span></div>
<div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;<span class="comment">        //! \tparam TIdx The idx type of the accelerator device properties.</span></div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;<span class="comment">        //! \tparam TKernelFn Kernel function object type.</span></div>
<div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;<span class="comment">        //! \tparam TArgs Kernel function object argument types as a parameter pack.</span></div>
<div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;<span class="comment"></span>        <span class="keyword">template</span>&lt;<span class="keyword">typename</span> TApi, <span class="keyword">typename</span> TDev, <span class="keyword">typename</span> TDim, <span class="keyword">typename</span> TIdx, <span class="keyword">typename</span> TKernelFn, <span class="keyword">typename</span>... TArgs&gt;</div>
<div class="line"><a name="l00307"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1FunctionAttributes_3_01AccGpuUniformCudaHipRt_3_01TApi_00_01TDim_00_01Td823296610d36653ab337d06ff7f2698.html">  307</a></span>&#160;        <span class="keyword">struct </span><a class="code" href="structalpaka_1_1trait_1_1FunctionAttributes.html">FunctionAttributes</a>&lt;<a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt</a>&lt;TApi, TDim, TIdx&gt;, TDev, TKernelFn, TArgs...&gt;</div>
<div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;        {<span class="comment"></span></div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;<span class="comment">            //! \param dev The device instance</span></div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;<span class="comment">            //! \param kernelFn The kernel function object which should be executed.</span></div>
<div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;<span class="comment">            //! \param args The kernel invocation arguments.</span></div>
<div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;<span class="comment">            //! \return KernelFunctionAttributes instance. The default version always returns an instance with zero</span></div>
<div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;<span class="comment">            //! fields. For CPU, the field of max threads allowed by kernel function for the block is 1.</span></div>
<div class="line"><a name="l00314"></a><span class="lineno"><a class="line" href="structalpaka_1_1trait_1_1FunctionAttributes_3_01AccGpuUniformCudaHipRt_3_01TApi_00_01TDim_00_01Td823296610d36653ab337d06ff7f2698.html#a6270e8acef72cf392e5be9089a23f5ae">  314</a></span>&#160;<span class="comment"></span>            <a class="code" href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a> <span class="keyword">static</span> <span class="keyword">auto</span> <a class="code" href="structalpaka_1_1trait_1_1FunctionAttributes_3_01AccGpuUniformCudaHipRt_3_01TApi_00_01TDim_00_01Td823296610d36653ab337d06ff7f2698.html#a6270e8acef72cf392e5be9089a23f5ae">getFunctionAttributes</a>(</div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;                [[maybe_unused]] TDev <span class="keyword">const</span>&amp; dev,</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;                [[maybe_unused]] TKernelFn <span class="keyword">const</span>&amp; kernelFn,</div>
<div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;                [[maybe_unused]] TArgs&amp;&amp;... args) -&gt; <a class="code" href="structalpaka_1_1KernelFunctionAttributes.html">alpaka::KernelFunctionAttributes</a></div>
<div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;            {</div>
<div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;                <span class="keyword">auto</span> kernelName = <a class="code" href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">alpaka::detail::gpuKernel</a>&lt;</div>
<div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;                    TKernelFn,</div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;                    TApi,</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;                    <a class="code" href="classalpaka_1_1AccGpuUniformCudaHipRt.html">AccGpuUniformCudaHipRt&lt;TApi, TDim, TIdx&gt;</a>,</div>
<div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;                    TDim,</div>
<div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                    TIdx,</div>
<div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                    <a class="code" href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">remove_restrict_t&lt;std::decay_t&lt;TArgs&gt;</a>&gt;...&gt;;</div>
<div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160; </div>
<div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                <span class="keyword">typename</span> TApi::FuncAttributes_t funcAttrs;</div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;<span class="preprocessor">#        if BOOST_COMP_GNUC</span></div>
<div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;                <span class="comment">// Disable and enable compile warnings for gcc</span></div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;<span class="preprocessor">#            pragma GCC diagnostic push</span></div>
<div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;<span class="preprocessor">#            pragma GCC diagnostic ignored &quot;-Wconditionally-supported&quot;</span></div>
<div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;                <a class="code" href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a>(</div>
<div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;                    TApi::funcGetAttributes(&amp;funcAttrs, <span class="keyword">reinterpret_cast&lt;</span><span class="keywordtype">void</span> const*<span class="keyword">&gt;</span>(kernelName)));</div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;<span class="preprocessor">#        if BOOST_COMP_GNUC</span></div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;<span class="preprocessor">#            pragma GCC diagnostic pop</span></div>
<div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160; </div>
<div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;                <a class="code" href="structalpaka_1_1KernelFunctionAttributes.html">alpaka::KernelFunctionAttributes</a> kernelFunctionAttributes;</div>
<div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#a1fc6475fe28a4d2346a72501792bf90d">constSizeBytes</a> = funcAttrs.constSizeBytes;</div>
<div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#a37667b6abd0077384fcf54d35620ecca">localSizeBytes</a> = funcAttrs.localSizeBytes;</div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#a62c9eb8bcec83c72a04515693e47dec5">sharedSizeBytes</a> = funcAttrs.sharedSizeBytes;</div>
<div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#ac7edfb6d5b99bb259e3e54cf5fe9f398">maxDynamicSharedSizeBytes</a> = funcAttrs.maxDynamicSharedSizeBytes;</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#afd86dd13530c90a956983b6b554ee2ab">numRegs</a> = funcAttrs.numRegs;</div>
<div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#af957e27c58417ea1b6d289c4d565e97f">asmVersion</a> = funcAttrs.ptxVersion;</div>
<div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;                kernelFunctionAttributes.<a class="code" href="structalpaka_1_1KernelFunctionAttributes.html#a6f6de3aec1d4fed5a751b6e505406763">maxThreadsPerBlock</a> = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(funcAttrs.maxThreadsPerBlock);</div>
<div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160; </div>
<div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;<span class="preprocessor">#        if ALPAKA_DEBUG &gt;= ALPAKA_DEBUG_FULL</span></div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;                printf(<span class="stringliteral">&quot;Kernel Function Attributes: \n&quot;</span>);</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                printf(<span class="stringliteral">&quot;binaryVersion: %d \n&quot;</span>, funcAttrs.binaryVersion);</div>
<div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;                printf(</div>
<div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;                    <span class="stringliteral">&quot;constSizeBytes: %lu \n localSizeBytes: %lu, sharedSizeBytes %lu  maxDynamicSharedSizeBytes: %d &quot;</span></div>
<div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;                    <span class="stringliteral">&quot;\n&quot;</span>,</div>
<div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;                    funcAttrs.constSizeBytes,</div>
<div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;                    funcAttrs.localSizeBytes,</div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;                    funcAttrs.sharedSizeBytes,</div>
<div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;                    funcAttrs.maxDynamicSharedSizeBytes);</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160; </div>
<div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;                printf(</div>
<div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;                    <span class="stringliteral">&quot;numRegs: %d, ptxVersion: %d \n maxThreadsPerBlock: %d .\n &quot;</span>,</div>
<div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;                    funcAttrs.numRegs,</div>
<div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;                    funcAttrs.ptxVersion,</div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;                    funcAttrs.maxThreadsPerBlock);</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;<span class="preprocessor">#        endif</span></div>
<div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;                <span class="keywordflow">return</span> kernelFunctionAttributes;</div>
<div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;            }</div>
<div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;        };</div>
<div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;    } <span class="comment">// namespace trait</span></div>
<div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;} <span class="comment">// namespace alpaka</span></div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160; </div>
<div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;<span class="preprocessor">#    endif</span></div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160; </div>
<div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;<span class="preprocessor">#endif</span></div>
<div class="ttc" id="aAccGpuUniformCudaHipRt_8hpp_html"><div class="ttname"><a href="AccGpuUniformCudaHipRt_8hpp.html">AccGpuUniformCudaHipRt.hpp</a></div></div>
<div class="ttc" id="aBoostPredef_8hpp_html"><div class="ttname"><a href="BoostPredef_8hpp.html">BoostPredef.hpp</a></div></div>
<div class="ttc" id="aCuda_8hpp_html"><div class="ttname"><a href="Cuda_8hpp.html">Cuda.hpp</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_a6a8e5f5a48b0bff7946528ab4e3e9f62"><div class="ttname"><a href="Debug_8hpp.html#a6a8e5f5a48b0bff7946528ab4e3e9f62">ALPAKA_DEBUG_MINIMAL</a></div><div class="ttdeci">#define ALPAKA_DEBUG_MINIMAL</div><div class="ttdoc">The minimal debug level.</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00016">Debug.hpp:16</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_a7f84384a17e301a636770e17c2951383"><div class="ttname"><a href="Debug_8hpp.html#a7f84384a17e301a636770e17c2951383">ALPAKA_DEBUG</a></div><div class="ttdeci">#define ALPAKA_DEBUG</div><div class="ttdoc">Set the minimum log level if it is not defined.</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00022">Debug.hpp:22</a></div></div>
<div class="ttc" id="aDebug_8hpp_html_ac556c317f934c69c8c8c083c5068f681"><div class="ttname"><a href="Debug_8hpp.html#ac556c317f934c69c8c8c083c5068f681">ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</a></div><div class="ttdeci">#define ALPAKA_DEBUG_MINIMAL_LOG_SCOPE</div><div class="ttdef"><b>Definition:</b> <a href="Debug_8hpp_source.html#l00055">Debug.hpp:55</a></div></div>
<div class="ttc" id="aDecay_8hpp_html"><div class="ttname"><a href="Decay_8hpp.html">Decay.hpp</a></div></div>
<div class="ttc" id="aDemangleTypeNames_8hpp_html"><div class="ttname"><a href="DemangleTypeNames_8hpp.html">DemangleTypeNames.hpp</a></div></div>
<div class="ttc" id="aDevUniformCudaHipRt_8hpp_html"><div class="ttname"><a href="DevUniformCudaHipRt_8hpp.html">DevUniformCudaHipRt.hpp</a></div></div>
<div class="ttc" id="aHip_8hpp_html"><div class="ttname"><a href="Hip_8hpp.html">Hip.hpp</a></div></div>
<div class="ttc" id="aKernelFunctionAttributes_8hpp_html"><div class="ttname"><a href="KernelFunctionAttributes_8hpp.html">KernelFunctionAttributes.hpp</a></div></div>
<div class="ttc" id="aQueueUniformCudaHipRt_8hpp_html"><div class="ttname"><a href="QueueUniformCudaHipRt_8hpp.html">QueueUniformCudaHipRt.hpp</a></div></div>
<div class="ttc" id="aRemoveRestrict_8hpp_html"><div class="ttname"><a href="RemoveRestrict_8hpp.html">RemoveRestrict.hpp</a></div></div>
<div class="ttc" id="aUniformCudaHip_8hpp_html_aad1e1de5a82a5f770453aed02324a99f"><div class="ttname"><a href="UniformCudaHip_8hpp.html#aad1e1de5a82a5f770453aed02324a99f">ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK</a></div><div class="ttdeci">#define ALPAKA_UNIFORM_CUDA_HIP_RT_CHECK(cmd)</div><div class="ttdoc">CUDA/HIP runtime error checking with log and exception.</div><div class="ttdef"><b>Definition:</b> <a href="UniformCudaHip_8hpp_source.html#l00105">UniformCudaHip.hpp:105</a></div></div>
<div class="ttc" id="aWorkDivHelpers_8hpp_html"><div class="ttname"><a href="WorkDivHelpers_8hpp.html">WorkDivHelpers.hpp</a></div></div>
<div class="ttc" id="aWorkDivMembers_8hpp_html"><div class="ttname"><a href="WorkDivMembers_8hpp.html">WorkDivMembers.hpp</a></div></div>
<div class="ttc" id="aacc_2Traits_8hpp_html"><div class="ttname"><a href="acc_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aclassalpaka_1_1AccGpuUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1AccGpuUniformCudaHipRt.html">alpaka::AccGpuUniformCudaHipRt</a></div><div class="ttdoc">The GPU CUDA accelerator.</div><div class="ttdef"><b>Definition:</b> <a href="AccGpuUniformCudaHipRt_8hpp_source.html#l00050">AccGpuUniformCudaHipRt.hpp:71</a></div></div>
<div class="ttc" id="aclassalpaka_1_1DevUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1DevUniformCudaHipRt.html">alpaka::DevUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT device handle.</div><div class="ttdef"><b>Definition:</b> <a href="DevUniformCudaHipRt_8hpp_source.html#l00056">DevUniformCudaHipRt.hpp:59</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html">alpaka::TaskKernelGpuUniformCudaHipRt</a></div><div class="ttdoc">The GPU CUDA/HIP accelerator execution task.</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00121">TaskKernelGpuUniformCudaHipRt.hpp:122</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a35fc3725cde6251430e0930d4a8ee681"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a35fc3725cde6251430e0930d4a8ee681">alpaka::TaskKernelGpuUniformCudaHipRt::m_kernelFnObj</a></div><div class="ttdeci">TKernelFnObj m_kernelFnObj</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00138">TaskKernelGpuUniformCudaHipRt.hpp:138</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a81cbbfab8168bd34880ce326a25d83aa"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a81cbbfab8168bd34880ce326a25d83aa">alpaka::TaskKernelGpuUniformCudaHipRt::m_args</a></div><div class="ttdeci">std::tuple&lt; remove_restrict_t&lt; std::decay_t&lt; TArgs &gt; &gt;... &gt; m_args</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00139">TaskKernelGpuUniformCudaHipRt.hpp:139</a></div></div>
<div class="ttc" id="aclassalpaka_1_1TaskKernelGpuUniformCudaHipRt_html_a8670d9407b302e594f922885e5b9d1e9"><div class="ttname"><a href="classalpaka_1_1TaskKernelGpuUniformCudaHipRt.html#a8670d9407b302e594f922885e5b9d1e9">alpaka::TaskKernelGpuUniformCudaHipRt::TaskKernelGpuUniformCudaHipRt</a></div><div class="ttdeci">ALPAKA_FN_HOST TaskKernelGpuUniformCudaHipRt(TWorkDiv &amp;&amp;workDiv, TKernelFnObj const &amp;kernelFnObj, TArgs &amp;&amp;... args)</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00125">TaskKernelGpuUniformCudaHipRt.hpp:125</a></div></div>
<div class="ttc" id="aclassalpaka_1_1Vec_html"><div class="ttname"><a href="classalpaka_1_1Vec.html">alpaka::Vec&lt; TDim, TIdx &gt;</a></div></div>
<div class="ttc" id="aclassalpaka_1_1WorkDivMembers_html"><div class="ttname"><a href="classalpaka_1_1WorkDivMembers.html">alpaka::WorkDivMembers</a></div><div class="ttdoc">A basic class holding the work division as grid block extent, block thread and thread element extent.</div><div class="ttdef"><b>Definition:</b> <a href="WorkDivMembers_8hpp_source.html#l00019">WorkDivMembers.hpp:20</a></div></div>
<div class="ttc" id="aclassalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_html"><div class="ttname"><a href="classalpaka_1_1uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt.html">alpaka::uniform_cuda_hip::detail::QueueUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT queue.</div><div class="ttdef"><b>Definition:</b> <a href="QueueUniformCudaHipRt_8hpp_source.html#l00093">QueueUniformCudaHipRt.hpp:97</a></div></div>
<div class="ttc" id="acore_2Common_8hpp_html_a30cf38ce8c63908b355f69eb893da575"><div class="ttname"><a href="core_2Common_8hpp.html#a30cf38ce8c63908b355f69eb893da575">ALPAKA_FN_HOST</a></div><div class="ttdeci">#define ALPAKA_FN_HOST</div><div class="ttdef"><b>Definition:</b> <a href="core_2Common_8hpp_source.html#l00040">Common.hpp:40</a></div></div>
<div class="ttc" id="adev_2Traits_8hpp_html"><div class="ttname"><a href="dev_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="adim_2Traits_8hpp_html"><div class="ttname"><a href="dim_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aidx_2Traits_8hpp_html"><div class="ttname"><a href="idx_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="akernel_2Traits_8hpp_html"><div class="ttname"><a href="kernel_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1detail_html_a64053dbfaaaefdf2572ec83b38b30623"><div class="ttname"><a href="namespacealpaka_1_1detail.html#a64053dbfaaaefdf2572ec83b38b30623">alpaka::detail::gpuKernel</a></div><div class="ttdeci">__global__ void gpuKernel(Vec&lt; TDim, TIdx &gt; const threadElemExtent, TKernelFnObj const kernelFnObj, TArgs... args)</div><div class="ttdoc">The GPU CUDA/HIP kernel entry point.</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00062">TaskKernelGpuUniformCudaHipRt.hpp:62</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1math_html_ad1a3c72853dc08a5e54e532f25a08988"><div class="ttname"><a href="namespacealpaka_1_1math.html#ad1a3c72853dc08a5e54e532f25a08988">alpaka::math::min</a></div><div class="ttdeci">ALPAKA_NO_HOST_ACC_WARNING ALPAKA_FN_HOST_ACC auto min(T const &amp;min_ctx, Tx const &amp;x, Ty const &amp;y)</div><div class="ttdoc">Returns the smaller of two arguments. NaNs are treated as missing data (between a NaN and a numeric v...</div><div class="ttdef"><b>Definition:</b> <a href="math_2Traits_8hpp_source.html#l01280">Traits.hpp:1280</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1uniform__cuda__hip_1_1detail_html_a552124cfd6ee8654baa53bc1710c0974"><div class="ttname"><a href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#a552124cfd6ee8654baa53bc1710c0974">alpaka::uniform_cuda_hip::detail::convertVecToUniformCudaHipDim</a></div><div class="ttdeci">ALPAKA_FN_HOST auto convertVecToUniformCudaHipDim(Vec&lt; TDim, TIdx &gt; const &amp;vec) -&gt; dim3</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00104">TaskKernelGpuUniformCudaHipRt.hpp:104</a></div></div>
<div class="ttc" id="anamespacealpaka_1_1uniform__cuda__hip_1_1detail_html_af9741bdf6dda9699e1dd8ca18d81d16a"><div class="ttname"><a href="namespacealpaka_1_1uniform__cuda__hip_1_1detail.html#af9741bdf6dda9699e1dd8ca18d81d16a">alpaka::uniform_cuda_hip::detail::checkVecOnly3Dim</a></div><div class="ttdeci">ALPAKA_FN_HOST auto checkVecOnly3Dim(Vec&lt; TDim, TIdx &gt; const &amp;vec) -&gt; void</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00087">TaskKernelGpuUniformCudaHipRt.hpp:87</a></div></div>
<div class="ttc" id="anamespacealpaka_html"><div class="ttname"><a href="namespacealpaka.html">alpaka</a></div><div class="ttdoc">The alpaka accelerator library.</div><div class="ttdef"><b>Definition:</b> <a href="AccCpuOmp2Blocks_8hpp_source.html#l00048">AccCpuOmp2Blocks.hpp:49</a></div></div>
<div class="ttc" id="anamespacealpaka_html_a78675a272ead29bbbf706b20727fa209"><div class="ttname"><a href="namespacealpaka.html#a78675a272ead29bbbf706b20727fa209">alpaka::remove_restrict_t</a></div><div class="ttdeci">typename remove_restrict&lt; T &gt;::type remove_restrict_t</div><div class="ttdoc">Helper to remove restrict from a type.</div><div class="ttdef"><b>Definition:</b> <a href="RemoveRestrict_8hpp_source.html#l00034">RemoveRestrict.hpp:34</a></div></div>
<div class="ttc" id="anamespacealpaka_html_aa4fe5980725182b3306caf3167053a75"><div class="ttname"><a href="namespacealpaka.html#aa4fe5980725182b3306caf3167053a75">alpaka::getDev</a></div><div class="ttdeci">ALPAKA_FN_HOST auto getDev(T const &amp;t)</div><div class="ttdef"><b>Definition:</b> <a href="dev_2Traits_8hpp_source.html#l00068">Traits.hpp:68</a></div></div>
<div class="ttc" id="anamespacealpaka_html_ac49b3c4b09c8a7455e8f88faa51484df"><div class="ttname"><a href="namespacealpaka.html#ac49b3c4b09c8a7455e8f88faa51484df">alpaka::getAccName</a></div><div class="ttdeci">ALPAKA_FN_HOST auto getAccName() -&gt; std::string</div><div class="ttdef"><b>Definition:</b> <a href="acc_2Traits_8hpp_source.html#l00100">Traits.hpp:100</a></div></div>
<div class="ttc" id="anamespacealpaka_html_aee3fb80b82e8f3e9601195afb0b8c34c"><div class="ttname"><a href="namespacealpaka.html#aee3fb80b82e8f3e9601195afb0b8c34c">alpaka::Dim</a></div><div class="ttdeci">typename trait::DimType&lt; T &gt;::type Dim</div><div class="ttdoc">The dimension type trait alias template to remove the ::type.</div><div class="ttdef"><b>Definition:</b> <a href="dim_2Traits_8hpp_source.html#l00019">Traits.hpp:19</a></div></div>
<div class="ttc" id="aplatform_2Traits_8hpp_html"><div class="ttname"><a href="platform_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="aqueue_2Traits_8hpp_html"><div class="ttname"><a href="queue_2Traits_8hpp.html">Traits.hpp</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html">alpaka::KernelFunctionAttributes</a></div><div class="ttdoc">Kernel function attributes struct. Attributes are filled by calling the API of the accelerator using ...</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00014">KernelFunctionAttributes.hpp:15</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_a1fc6475fe28a4d2346a72501792bf90d"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#a1fc6475fe28a4d2346a72501792bf90d">alpaka::KernelFunctionAttributes::constSizeBytes</a></div><div class="ttdeci">std::size_t constSizeBytes</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00016">KernelFunctionAttributes.hpp:16</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_a37667b6abd0077384fcf54d35620ecca"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#a37667b6abd0077384fcf54d35620ecca">alpaka::KernelFunctionAttributes::localSizeBytes</a></div><div class="ttdeci">std::size_t localSizeBytes</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00017">KernelFunctionAttributes.hpp:17</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_a62c9eb8bcec83c72a04515693e47dec5"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#a62c9eb8bcec83c72a04515693e47dec5">alpaka::KernelFunctionAttributes::sharedSizeBytes</a></div><div class="ttdeci">std::size_t sharedSizeBytes</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00018">KernelFunctionAttributes.hpp:18</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_a6f6de3aec1d4fed5a751b6e505406763"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#a6f6de3aec1d4fed5a751b6e505406763">alpaka::KernelFunctionAttributes::maxThreadsPerBlock</a></div><div class="ttdeci">int maxThreadsPerBlock</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00023">KernelFunctionAttributes.hpp:23</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_ac7edfb6d5b99bb259e3e54cf5fe9f398"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#ac7edfb6d5b99bb259e3e54cf5fe9f398">alpaka::KernelFunctionAttributes::maxDynamicSharedSizeBytes</a></div><div class="ttdeci">int maxDynamicSharedSizeBytes</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00019">KernelFunctionAttributes.hpp:19</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_af957e27c58417ea1b6d289c4d565e97f"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#af957e27c58417ea1b6d289c4d565e97f">alpaka::KernelFunctionAttributes::asmVersion</a></div><div class="ttdeci">int asmVersion</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00022">KernelFunctionAttributes.hpp:22</a></div></div>
<div class="ttc" id="astructalpaka_1_1KernelFunctionAttributes_html_afd86dd13530c90a956983b6b554ee2ab"><div class="ttname"><a href="structalpaka_1_1KernelFunctionAttributes.html#afd86dd13530c90a956983b6b554ee2ab">alpaka::KernelFunctionAttributes::numRegs</a></div><div class="ttdeci">int numRegs</div><div class="ttdef"><b>Definition:</b> <a href="KernelFunctionAttributes_8hpp_source.html#l00020">KernelFunctionAttributes.hpp:20</a></div></div>
<div class="ttc" id="astructalpaka_1_1PlatformUniformCudaHipRt_html"><div class="ttname"><a href="structalpaka_1_1PlatformUniformCudaHipRt.html">alpaka::PlatformUniformCudaHipRt</a></div><div class="ttdoc">The CUDA/HIP RT platform.</div><div class="ttdef"><b>Definition:</b> <a href="PlatformUniformCudaHipRt_8hpp_source.html#l00029">PlatformUniformCudaHipRt.hpp:30</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1AccType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1AccType.html">alpaka::trait::AccType</a></div><div class="ttdoc">The accelerator type trait.</div><div class="ttdef"><b>Definition:</b> <a href="acc_2Traits_8hpp_source.html#l00037">Traits.hpp:37</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DevType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1DevType.html">alpaka::trait::DevType</a></div><div class="ttdoc">The device type trait.</div><div class="ttdef"><b>Definition:</b> <a href="dev_2Traits_8hpp_source.html#l00023">Traits.hpp:23</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1_html_ad31779fde1a2b8cf69e2e330b969d07a"><div class="ttname"><a href="structalpaka_1_1trait_1_1DimType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_d937d18cc35a2c3a9b92b7f6271c43f1.html#ad31779fde1a2b8cf69e2e330b969d07a">alpaka::trait::DimType&lt; TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::type</a></div><div class="ttdeci">TDim type</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00162">TaskKernelGpuUniformCudaHipRt.hpp:162</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1DimType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1DimType.html">alpaka::trait::DimType</a></div><div class="ttdoc">The dimension getter type trait.</div><div class="ttdef"><b>Definition:</b> <a href="dim_2Traits_8hpp_source.html#l00014">Traits.hpp:14</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1Enqueue_3_01uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_3_01Tcf5f0cfca5b539ecd63517c701535324_html_add361fe22454f8fb779829af220da54c"><div class="ttname"><a href="structalpaka_1_1trait_1_1Enqueue_3_01uniform__cuda__hip_1_1detail_1_1QueueUniformCudaHipRt_3_01Tcf5f0cfca5b539ecd63517c701535324.html#add361fe22454f8fb779829af220da54c">alpaka::trait::Enqueue&lt; uniform_cuda_hip::detail::QueueUniformCudaHipRt&lt; TApi, TBlocking &gt;, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::enqueue</a></div><div class="ttdeci">static ALPAKA_FN_HOST auto enqueue(uniform_cuda_hip::detail::QueueUniformCudaHipRt&lt; TApi, TBlocking &gt; &amp;queue, TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; const &amp;task) -&gt; void</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00192">TaskKernelGpuUniformCudaHipRt.hpp:192</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1Enqueue_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1Enqueue.html">alpaka::trait::Enqueue</a></div><div class="ttdoc">The queue enqueue trait.</div><div class="ttdef"><b>Definition:</b> <a href="queue_2Traits_8hpp_source.html#l00027">Traits.hpp:27</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1FunctionAttributes_3_01AccGpuUniformCudaHipRt_3_01TApi_00_01TDim_00_01Td823296610d36653ab337d06ff7f2698_html_a6270e8acef72cf392e5be9089a23f5ae"><div class="ttname"><a href="structalpaka_1_1trait_1_1FunctionAttributes_3_01AccGpuUniformCudaHipRt_3_01TApi_00_01TDim_00_01Td823296610d36653ab337d06ff7f2698.html#a6270e8acef72cf392e5be9089a23f5ae">alpaka::trait::FunctionAttributes&lt; AccGpuUniformCudaHipRt&lt; TApi, TDim, TIdx &gt;, TDev, TKernelFn, TArgs... &gt;::getFunctionAttributes</a></div><div class="ttdeci">static ALPAKA_FN_HOST auto getFunctionAttributes([[maybe_unused]] TDev const &amp;dev, [[maybe_unused]] TKernelFn const &amp;kernelFn, [[maybe_unused]] TArgs &amp;&amp;... args) -&gt; alpaka::KernelFunctionAttributes</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00314">TaskKernelGpuUniformCudaHipRt.hpp:314</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1FunctionAttributes_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1FunctionAttributes.html">alpaka::trait::FunctionAttributes</a></div><div class="ttdoc">The structure template to access to the functions attributes of a kernel function object.</div><div class="ttdef"><b>Definition:</b> <a href="kernel_2Traits_8hpp_source.html#l00078">Traits.hpp:79</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b_html_a3661e7ff93f5ec2d0b6929c6a790f564"><div class="ttname"><a href="structalpaka_1_1trait_1_1IdxType_3_01TaskKernelGpuUniformCudaHipRt_3_01TApi_00_01TAcc_00_01TDim_822aa73fb65e90858803fa0d1659168b.html#a3661e7ff93f5ec2d0b6929c6a790f564">alpaka::trait::IdxType&lt; TaskKernelGpuUniformCudaHipRt&lt; TApi, TAcc, TDim, TIdx, TKernelFnObj, TArgs... &gt; &gt;::type</a></div><div class="ttdeci">TIdx type</div><div class="ttdef"><b>Definition:</b> <a href="TaskKernelGpuUniformCudaHipRt_8hpp_source.html#l00176">TaskKernelGpuUniformCudaHipRt.hpp:176</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1IdxType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1IdxType.html">alpaka::trait::IdxType</a></div><div class="ttdoc">The idx type trait.</div><div class="ttdef"><b>Definition:</b> <a href="idx_2Traits_8hpp_source.html#l00025">Traits.hpp:25</a></div></div>
<div class="ttc" id="astructalpaka_1_1trait_1_1PlatformType_html"><div class="ttname"><a href="structalpaka_1_1trait_1_1PlatformType.html">alpaka::trait::PlatformType</a></div><div class="ttdoc">The platform type trait.</div><div class="ttdef"><b>Definition:</b> <a href="platform_2Traits_8hpp_source.html#l00030">Traits.hpp:30</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="dir_f712bff28b6ff1ff870a222047d04675.html">alpaka</a></li><li class="navelem"><a class="el" href="dir_ddf4b6b668da48004ea34c8205023599.html">kernel</a></li><li class="navelem"><a class="el" href="TaskKernelGpuUniformCudaHipRt_8hpp.html">TaskKernelGpuUniformCudaHipRt.hpp</a></li>
    <li class="footer">Generated on Thu Sep 19 2024 07:53:19 for alpaka by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
